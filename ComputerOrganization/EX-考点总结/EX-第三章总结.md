# EX-第三章 存储系统总结

## 导读

### 【考纲内容】

1. **存储器的分类**
2. **层次化存储器的基本结构**
3. **半导体随机存取存储器**：$SRAM$、$DRAM$、$Flash$存储器
4. **主存储器**：$DRAM$芯片和内存条、多模块存储器、主存和 $CPU$之间的连接
5. **外部存储器**：磁盘存储器、固态硬盘$SSD$
6. **高速缓冲存储器**
    1. $Cache $的基本原理
    2. $Cache $和主存之间的映射方式
    3. $Cache $中主存块的替换算法;
    4. $Cache $写策略
7. **虚拟存储器**
    1. 虚拟存储器的基本概念
    2. 页式虚拟存储器：基本原理、页表、地址转换、快表$TLB $
    3. 段式虚拟存储器的基本原理
    4. 段页式虚拟存储器的基本原理

### 【复习提示】

选择题：存储器的特点，存储器的扩展（芯片选择、连接方式、地址范围等），交叉存储器，$Cache $的相关计算与替换算法，虚拟存储器与快表

综合题：$Cache $和虚拟存储器、$Cache $和 $TLB $的计算机中的地址翻译与 $Cache$ 映射问题。

## 考点总结

### 存储器的分类

1.   按作用分类：主存储器、辅助存储器、高速缓冲存储器$Cache$。
2.   按存取方式分类
     1.   随机存取：**与存储单元的物理位置无关**
          1.   随机存取存储器$RAM(Random\;Access\;Memory)$
               + 动态随机存取存储$DRAM$
               + 静态随机存取存储$SRAM$
          2.   只读存储器$ROM(Read-Only\;Memory)$
          3.   相联存储器$CAM(Content-Addressable\;Memory)$
     2.   串行访问：**读写某个存储单元所需时间与存储单元的物理位置有关**
          1.   直接存取$DAM$：磁盘。
          2.   顺序存取$SAM$：磁带。
3.   按存储介质分类
     1.   磁表面存储器：磁盘、磁带。
     2.   磁芯存储器。$MOS$型存储器、双极型存储器。
     3.   光存储器：光盘。
     4.   半导体存储器。
4.   按信息可保存性分类
     1.   断电后信息是否消失：
          + 易失性：$RAM(Cache，$主存$)$。
          + 非易失性：磁带、$ROM$。
     2.   破坏性，存取是否影响存储内存：
          + 破坏性读出：$DRAM$。
          + 非破坏性读出：$SRAM$

### 存储器概述

1.   存储器性能指标
     1.   存储容量：存储字数×字长（如$1M\times8$位）。
     2.   单位成本：每位价格=总成本÷总容量。

     3.   主存带宽（$B_m$）：主存带宽又称数据传输率，表示每秒从主存进出信息的最大数量，单位为字/秒、字节/秒（$B/s$）或位/秒（$b/s$）。

     4.   存储速度：数据传输率=数据的宽度(单位$B$)÷存储周期，其中存储周期=存取时间+恢复时间。
          1.   存取时间（$T_a$）：存取时间是指从启动一次存储器操作到完成该操作所经历平均的时间，分为读出时间和写入时间。
          2.   存取周期（$T_m$）：存取周期又称为读写周期或访问周期。它是指存储器进行一次完整的读写操作所需的金部时间，即连续两次独立地访问存储器操作（读或写操作）之间所需的最小时间间隔。
2.   存储器层次化结构：$CPU\to Cache\to$主存$\to$辅存$\to$虚拟存储系统。
     1.   在主存和$CPU$之间插入$Cache$是为了解决$CPU$的高速与主存之间的低速速度不匹配的问题，由硬件自动完成
     2.   在虚拟存储系统和主存之间插入辅存是为了解决主存容量不足的问题，由硬件和操作系统共同完成。
     3.   主存和$	Cache$之间的数据调动是由硬件自动完成的，对所有程序员均是透明的
     4.   而主存和辅存之间的数据调动则是由硬件和操作系统共同完成的，对应用程序员是透明的。

### 主存储器

![image-20231028180236086](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202310281802172.png)

1.   静态随机存储器$SRAM$：使用双稳态触发器六晶体管$MOS$来记忆信息，因此即使信息被读出后，仍保持其原状态而不需要再生，即非破坏性读出。$SRAM$的存取速度快，但集成度低，功耗较大，价格昂贵，一般用于高速缓冲存储器。
2.   动态随机存储器$DRAM$​：利用存储元电路中栅极电容上的电荷来存储信息的，$DRAM$的基本存储元通常只使用一个晶体管，所以它比$SRAM$的密度要高很多。$DRAM$容易集成、位价低、容量大和功耗低，但$DRAM$的存取速度较慢，一般用于大容量的主存系统。
     +   地址引脚复用：DRAM芯片容量较大，地址位数较多，为减少芯片的地址引脚数，采用地址引脚复用技术，**将地址拆分为行列地址**（$DRAM$行、列地址等长），这样地址引脚数可减少一半（**数据引脚数不减少**）。
         +   $SRAM$需要$2^n$条地址线，而$DRAM$需要$2^{\frac{n}{2}+1}$根地址线。
3.   $DRAM$的刷新：即使电源不断电，信息也会自动消失，故每隔一定时间必须刷新。
     1.   刷新周期：从上一次刷新结束到下一次对整个$DRAM$全部刷新一遍为止，一般为$2ms$。
     2.   刷新单元数：以行为单元，每次刷新一行存储单元。
     3.   刷新方式：硬件支持，读出一行的信息后重新写入整个行，占用一个读/写周期。
     4.   刷新时刻：内存只有⼀套地址译码和⽚选装置，刷新与存取有相似的过程，故么刷新与存取不能并⾏，刷新操作之间也不能并行。
          1.   集中刷新：有一段时间专门刷新，但是这时候就无法访问存储器，必须停⽌读/写操作，称为**访存死区**，该段时间为**死时间**。读写时间不受刷新工作的影响，但是存在死区。
          2.   分散刷新：每读取完一行数据就刷新一次。没有死区，但是加长了系统存取周期，降低整机速度。
          3.   异步刷新：隔一段时间刷新一次，一次要刷新所有的行，缩短了“死时间”，但任然存在“死时间”。可以避免使$CPU$连续等待过长的时间，而且减少了刷新次数，从根本上提高了整机的工作效率。
4.   ※$SRAM$和$DRAM$的引脚数：对于容量为$N\times M$位的存储器，其中$N=2^n$为存储单元个数，$M$为存储字长
     1.   $DRAM$使用地址线复用技术，地址线线路引脚数减少一半：地址线引脚数为$\frac{n}{2}$，数据线引脚数为$M$，读写控制线引脚数为$2$，需要一根行通选线和一根列通选线共两根。
     2.   $SRAM$未使用地址线复用技术：地址线引脚数为$n$，数据线引脚数为$M$，读写控制线引脚数为$2$，只需要一根片选线

### 只读存储器$ROM$

#### $ROM$的种类

只读存储器$ROM$**均为非易失性，断电后数据不会丢失**；结构简单，位密度比可读写存储器高

1.   掩模式只读存储器$MROM (Mask\;Read-Only\;Memory)$ ：厂家按照客户需求，在芯片生产过程中直接写入信息，之后任何人**不可重写，只能读出，无法修改**。可靠性高、灵活性差、生产周期长、只适合批量定制。
2.   可编程只读存储器$PROM (Programmable\;Read-Only\;Memory)$ ：用户可用专门的$PROM$写入器写入信息，之后无法修改
3.   可擦除只读存储器$EPROM (Erasable\;Programmable\;Read-Only\;Memory)$ ：允许用户写入信息，之后用某种方法擦除数据，**可进行多次重写**。不能取代$RAM$，因为$EPROM$的编程次数有限，且写入时间过长。
     1.   光可擦除只读存储器$UVEPROM (Ultraviolet\;Rays，$紫外线$)$ ：**擦除所有信息，无法特定擦除**
     2.   电可擦除只读存储器$EEPROM$(也常记为$E^2PROM$，第一个$E$是$Electrically$)：可用“电擦除”的方式擦除特定的字
4.   闪速存储器$Flash Memory$ ：在$EEPROM $基础上发展而来， 断电后也能保存信息，且**可进行多次快速擦除重写**。**U盘、SD卡就是闪存**。
     +  由于闪存需要先擦除再写入，因此**闪存的写速度比读速度要慢**
5.   固态硬盘$SSD (Solid \;State \;Drives)$ ：由控制单元+存储单元($Flash $芯片)构成，与闪速存储器的核心区别在于控制单元不一样，但存储介质都类似，**可进行多次快速擦除重写**。$SSD$速度快、功耗低、价格高。

#### 多模块存储器

1.   单体多字存储器：普通存储器是每行为一个存储单元，而对于单体多字存储器来说，每个存储单元存储$m$个字，若总线宽度也为$m$个字，则一次并行就能读出$m$个字。**但是只有数据和指令是连续存放在内存的才能这样操作，转移指令无效**。
2.   多体并行存储器：每个模块都有相同的容量和存取速度，以及独立的读写控制电路、地址寄存器和数据寄存器。地址分为体号和体内地址两个部分。对读取数据进行优化。（不是对传输数据）。

---

1.   高位交叉编址的多体存储器：高位是体号，低位是体内地址。**只是相当于扩容而已，对于速度没有改变**。对于连续访问连续地址时，只能一个个访问周期依次访问。若连续取$n$个存储字，每次访问需要$T$的时间，则耗时$nT$。
     +   可以理解成多根内存条，高位(体号)表示访问内存条编号，低位是体内地址
2.   低位交叉编址的多体存储器：**根据历年408真题的描述，交叉编址方式默认指低位交叉编址**。低位是体号，高位是体内地址。使用交叉存放，很好地满足了程序的局部性原理。**存储周期=总线周期×模块数**。
     1.   可以理解成多根内存条，低位(体号)表示访问内存条编号，高位是体内地址。
     2.   若模块字长等于数据总线宽度，模块存取一个字的存取周期为$T$，**总线传送周期(存取时间)**为$r$，所以存储器交叉模块数应该大于等于**交叉存取度**$m=\frac{T}{r}$。启动该模块后能保证经过$m\times r$的时间后再次使用该模块时上次存取操作已经完成。
     3.   若连续取$n$个存储字，每次访问需要$T$的时间，启动间隔为$\tau$，则耗时$T+(n-1)\tau$。

![image-20231028182548266](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202310281825377.png)

### 主存储器与$CPU$的连接

1.   位扩展法：增加存储器的位数，而字的数量不变。是将多个存储芯片的地址端、片选端和读写控制端相应并联，数据端分别引出。相当于上面低位交叉编址的多体存储器中每次读取每个内存条的数据。
     1.   地址总线和片选线都是并联的，数据总线连接在每一块芯片上。
     2.   因为需要拓展位，所以一次性需要处理所有芯片的数据，从而需要对芯片同时进行片选线同步信号，所以所有芯片的$\overline{CS}$都可以连接在一起。
     3.   每个芯片各输入输出一部分数据。
     4.   芯片地址分配时将每列并联的一组芯片视为同一个地址组
2.   字扩展法：增加存储器中字的数量（数据的地址大小即能保存的数据的数量），而位数不变。将芯片的地址线、数据线、读写控制线相应并联，而由片选信号来区分各芯片的地址范围。 但是如果每个芯片同时输入输出输数据则$CPU$无法区分到底是哪个芯片存储的数据，所以不能再将片选线连在一起同时控制。

![image-20230831215340072](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308312153187.png)

3.   字位同时扩展法：各芯片连接地址线的方式相同，但是连接数据线的方式不同，需要通过片选信号$\overline{CS}$或采用译码器设计连接到对应芯片。

![image-20230531221233861](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531221233861.png)

4.   存储芯片片选：要实现对存储单元的访问，首先要选择存储芯片，即进行片选；然后为选中的芯片依地址码选择相应的存储单元，以进行数据的存取，即进行字选。
     1.   线选法：当某地址线信息为`0`时，就选中与之对应的存储芯片，只能一位有效。不需要地址译码器，线路简单。但地址空间不连续，选片的地址线必须分时为低电平（否则不能工作)，不能充分利用系统的存储器空间，造成地址资源浪费。
     2.   译码片选法：由于译码器可以将$n$位映射到$2^n$位，通过地址译码芯片产生片选信号。地址空间可连续，可以增加逻辑设计。但电路逻辑复杂。

### 外部存储器

1.   独立冗余磁盘阵列$RAID $：指将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理内上分割交叉存储、并行访问，具有更好的存储性能、可靠性和安全性。无论何时有磁盘损坏，都可随时拔出受损的磁盘再插入好的磁盘，而数据不会损坏，提升了系统的可靠性。
     1.   $RAID0$： 无冗余和无校验的磁盘阵列。无容错能力。
     2.   $RAID1$： 镜像磁盘阵列。有容错能力，但成本翻倍。
     3.   $RAID2$： 采用纠错的海明码的磁盘阵列。
     4.   $RAID3$： 位交叉奇偶校验的磁盘阵列。
     5.   $RAID4$： 块交叉奇偶校验的磁盘阵列。
     6.   $RAID5$： 无独立校验的奇偶校验磁盘阵列。

2.   固态硬盘$SSD$：属于电可擦除$ROM$，即$EEROM$。使用$Flash $芯片**可进行多次快速擦除重写**。 由于$Flash $需要先擦除再写入，因此**写速度比读速度要慢**。
     1.   组成：闪存翻译层（负责管理闪存芯片中的数据存储和访问，找到对应的页$Page$）和存储单元（$Flash $芯片，每个芯片包含多个块$Block$，每个块包含多个页$Page$）
     2.   读写性能特性：
          1.   以页$Page$为单位读/写：相当于磁盘的扇区
          2.   以块$Block$为单位"擦除"，擦干净的块，其中的每页都可以写一次，读无限次
          3.   支持随机访问，系统给定一个逻辑地址，闪存翻译层可通过电路迅速定位到对应的物理地址
          4.   读快、写慢。要写的页如果有数据，则不能写入，需要将块内其他页全部复制到一个新的（擦除过的）块中，再写入新的页
     3.   与机械硬盘相比的特点：
          1.   $SSD$读写速度快，随机访问性能高，用电路控制访问位置；机械硬盘通过移动磁背旋转磁盘控制访可位直，有寻道的间和旋转延达
          2.   $SSD$安静无噪音、耐摔抗震、能耗低、造价更贵
          3.   $SSD$的一个"块"被擦除次数过多（重复写同一个块）可能会坏掉而机械硬盘的扇区不会因为写的次数太多而坏掉
     4.   磨损均衡技术：将“擦除”平均分布在各个块上，以提升使用寿命
          1.   动态磨损均衡：写入数据时，优先选择累计擦除次数少的新闪存块
          2.   静态磨损均衡：$SSD$监测并自动进行数据分配、迁移，让老旧的闪存块承担以读为主的储存任务，让较新的闪存块承担更多的写任务

### 高速缓冲存储器$Cache$

#### $Cache$概述

1.   局部性原理：高速缓冲技术就是利用局部性原理，把程序中正在使用的部分数据存放在一个高速的、容量较小的$Cache$中，使$CPU$的访存操作大多数针对$Cache$进行，从而提高程序的执行速度

     1.   时间局部性：程序所访问的数据在相邻时间也可能访问到。
     2.   空间局部性：程序所访问的数据的周围数据也可能访问到。

2.   基本工作原理：$Cache$位于存储器层次结构的顶层，通常由$SRAM$构成（**$DRAM$必须不断刷新不适合$TLB$和$Cache$**）。为便于$Cache$和主存间交换信息，$Cache$和主存都被划分为相等的块，$Cache$块又称$Cache$行，每块由若干字节组成，块的长度称为块长（$Cache$行长)。

     1.   由于$Cache$的容量和块数远小于主存，它**仅按照某种策略保存主存中最活跃的若干块的副本**。
     2.   读取与访问：整个过程全部由硬件实现。
          1.   当$CPU$发出读请求时，若访存地址在$Cache$中命中，就将此地址转换成$Cache$地址，直接对$Cache$进行读操作，不再继续访问主存。
          2.   若$Cache$不命中，则仍需访问主存，并把此字所在的块一次性地从主存调入$Cache$。
          3.   若此时$Cache$已满，则需根据某种替换算法，用这个块替换$Cache$中原来的某块信息。
     3.   $CPU$与$Cache$之间的数据交换以**字**为单位，而$Cache$与主存之间的数据交换则以**块**为单位。

3.   $Cache$地址：主存储器的地址包括主存块号和块内地址，而$Cache$的地址包含缓冲块号和块内地址，两个块内地址都是一样长的且完全相同的。$Cache$还有一个标记，用来说明$Cache$块与主存块的关系，等于此块在主存中的块号。

4.   详细工作流程：以先访问$Cache$未命中再访问主存型的计算机为例，

     1. $CPU$发出访问地址，从地址总线传输到$Cache$。
     2. 通过$Cache$主存地址映射变换结构，将主存地址转换为$Cache$地址，在$Cache$中寻址对应数据。
     3. 如果命中就访问$Cache$并取出指令通过数据总线返回$CPU$。
     4. 如果不命中，就直接访问主存，取出信息通过数据总线返回$CPU$，并把这个信息存储在$Cache$中。
     5. 需要检测$Cache$是否已满，如果不满就直接将新的主存块调入$Cache$进行存储。
     6. 若已经满了则通过$Cache$替换结构，执行替换算法腾出空位再调入。

5.   命中与未命中：其中命中表示主存块调入缓存，主存块与缓存块建立了对应关系，用标记记录与某缓存块建立了对应关系的主存块号，且**有效位为1**（表示当前存储单元存储数据）。未命中则相反。

     1.   命中率$H$：$CPU$欲访问的信息在$Cache$中的比率。命中率与$Cache$的容量和块长有关。在一个程序执行期间（每个程序的命中率可能不同），
          $$
          H=\dfrac{N_c}{N_c+N_m}
          $$

          $Cache$的总命中次数为$N_c$，访问主存的总次数为$N_m$

     2. 平均访问时间$t$：$t_c$为访问一次$Cache$所需时间，$H$是命中率，$t_m$为访问一次主存所需时间

         + 若先访问$Cache$​未命中再访问主存，则
             $$
             t=Ht_c+(1-H)(t_c+t_m)
             $$

         + 若同时访问$Cache$​和主存，则
             $$
             t=Ht_c+(1-H)t_m
             $$

     3. 访问效率$e$：效率与命中率有关，$e=$访问$Cache$的时间/平均访问时间$\times100\%$​。假如$Cache$和主存是**同时被访问的**，则
         $$
         e=\dfrac{t_c}{h\times t_c+(1-h)\times t_m}\times100\%
         $$
         其中，$h$为$Cache$命中率，$t_c$为访问$Cache$的时间，$t_m$为访问主存的时间。

         当$h=0$时最小为$\dfrac{t_c}{t_m}$，当$h=1$时最大为$1$。

6.   $Cache$替换算法：即$Cache$中存储满了如何处理。对于直接映射法来说，固定替换出前一个数据存入此时的数据，所以**替换算法只针对全相联映射和组相联映射**。

     1.   随机$RAND$算法：随机地确定替换的$Cache$块。它的实现比较简单，但没有依据程序访问的局部性原理，故可能命中率较低。但是这种方式基本上不会使用。
     2.   先进先出置换算法$FIFO$：把调入$Cache$块的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可，队列的最大长度取决于系统为进程分配了多少个$Cache$块。使用队列实现，是队列类算法。实现简单，但是性能较差。
     3.   最近最久未使用置换算法$LRU$：依据程序访问的局部性原理选择近期内长久未访问过的存储行作为替换的行，平均命中率要比$FIFO$要高，是堆栈类算法，是一种局部性策略。**若被频繁访问的主存块数量>$Cache$行的数量，则有可能发生“抖动”**。

7.   写策略：即$Cache$中内容修改后如何让主存于$Cache$修改的保持一致。命中：全写法、写回法。不命中：写分配法、非写分配法。

     1.   回写法：当$CPU$对$Cache$写命中时**，只修改$Cache$的内容**，而**不立即写入主存**，只有当此块被换出时才写回主存（全部改完了再写回主存）。
          1.   减少了访存次数，但存在数据不一致的隐患。
          2.   需要在信息位中使用一个类似于有效位的**脏位/修改位**，修改位为1说明对应Cache行中的块被修改过，替换时需要写回主存。
     2.   全写法/直写策略：当$CPU$对$Cache$写命中时，必须把数据**同时写入$Cache$和主存**，当某一块需要替换时，不必把这一块写回主存，用新调入的块直接覆盖即可。
          1.   实现简单，能随时保持主存数据的正确性。缺点是增加了访存次数，降低了 $Cache$的效率。
          2.   由于写$Cache$要远快于写主存，所以一般使用$SRAM$实现的**写缓冲**$Write\;Buffer$暂存写入的数据，但是如果**写的速度过快可能会出现饱和溢出**。$CPU$同时将数据写到$Cache$和写缓冲中，写缓冲再将内容写入主存。写缓冲是一个$FIFO$队列，写缓冲可以解决速度不匹配的问题。
     3.   写分配法：加载主存中的块到$Cache$中，然后更新这个$Cache$块，即写完$Cache$之后再把$Cache$的值覆盖在主存的数据上，所以也需要设置一个脏位。**搭配回写法使用**。缺点是每次不命中都需要从主存中读取一块。
     4.   非写分配法：只写入主存，不调入$Cache$。**搭配全写法使用**。
     5.   多级$Cache$：将指令$Cache$和数据$Cache$分开设计。与$CPU$直接连接的第一层$Cache$使用全写法，在与主存直接连接的第二层$Cache$使用写回法。离CPU越近的速度越快，容量越小；离CPU越远的速度越慢，容量越大。

#### ※※地址映射

指把主存地址空间映射到$Cache$地址空间，即把存放在主存中的信息按照某种规则装入$Cache$。默认都需要一位有效位，有效位指当前块的地址有效 。**主存字块标记为主存容量除以$Cache$容量，表示要用多少位来区分主存地址**。

1.   全相联映射：主存中的每一块可以装入$Cache$中的任何位置，每行的标记用于指出该行取自主存的哪一块。随机选择空位：空位随意放（做题可以按从零开始顺序放）。
     1.   **地址组成：主存字块标记+字块内地址。**
     2.   附加位：一位有效位。
     3.   优点：比较灵活。冲突概率低。空间利用率高。命中率高。
     4.   缺点：标记比较速度慢。实现成本高（常需采用昂贵的按内容寻址的**相联存储器**进行地址映射）。
2.   直接映射：对号入座，每一个主存块只能存放在唯一一个地方。若这个位置已有内容，则产生块冲突，原来的块将无条件地被替换出去。**无须使用替换算法**。将主存长度对$Cache$长度取模，地址相同余数的内存块（行号相同）放在同一个$Cache$块中。$Cache$中的行号隐含（顺序存储，类似数组）。
     1.   **地址组成：主存字块标记+$Cache$行号+字块内地址。其中行号表示一共有多少个$Cache$行。**
     2.   附加位：一位有效位。若发生冲突，不需要替换算法直接替换出去，**所以不需要替换位**。
     3.   优点：不需要使用$Cache$字块标记，有效位存储的地址减少。实现难度降低。
     4.   缺点：不够灵活，即使$Cache$的其他许多地址空着也不能占用，导致**直接映射的块冲突概率最高，空间利用率最低**。
3.   组相联映射：按号分组，组内随意放。将$Cache$的块分为$Q$个大小相等的组，主存利用$Cache$组的个数进行模运算。当$Q=1$时变为全相联映射，当$Q= Cache$行数时变为直接映射。每组有$r$个行，则称为$r$路组相联。$N$路组相联映射方式，实质上就是将$N$个$Cache$行合并，内部采用全相联方式，外部采用直接映射方式。**路数越大，**即每组$Cache$行的数量越大，**发生块冲突的概率越低**，但相联比较电路也越复杂。 选定适当的数量，可使组相联映射的成本接近直接映射，而性能上仍接近全相联映射。
     1.   **地址组成：主存字块标记+$Cache$组号+字块内地址**。
     2.   附加位：一位有效位。
4.   地址映射总结：当$Cache$大小、主存块大小一定时，
     1.   直接映射的命中率最低，全相联映射的命中率最高。
     2.   直接映射的判断开销最小、所需时间最短，全相联映射的判断开销最大、所需时间最长。
     3.   直接映射标记所占的额外空间开销最少，全相联映射标记所占的额外空间开销最大。
5.   $Cache$标记项：$Cache$的总位数=一个标记项总位数$\times$总标记项数（$Cache$行总数）。每个$Cache$行对应一个标记项，标记项中应包括：
     1.   每行存储的数据：即$Cache$行长，计算时常转换为$bit$。
     2.   标记字段：需要计算，主存位数$-$字块内位数$-$（$Cache$行数$\mathcal{{\normalsize OR} } Cache$组数）。
     3.   有效位：一位。
     4.   一致性维护位，“脏”位，仅**回写法/写分配法**：一位。
     5.   替换算法位控制位，仅最近最久未使用置换算法$LRU$：对于$r$路组相联，替换算法位长度为$log_{2}r$。

### 虚拟存储器

#### 虚拟存储器概述

$Cache$为了解决主存和$CPU$之间的问题，而虚拟存储器为了解决主存和辅存之间的问题。虚拟存储器包括主存和辅存，将主存和辅存联合在一起统一编址。虚拟系统中，找到的地址后，**进行地址映射是靠操作系统完成**。

虚拟存储机制通常采用全相联映射，在处理一致性问题时，采用回写法。

用户编程允许涉及的地址称为**虚地址**或**逻辑地址**，虚地址对应的存储空间称为**虚拟空间**或**程序空间**，**虚拟空间由机器字长位数决定**。

1.   页表/慢表$Page$：虚页地址分为虚页号和页内地址，实页地址分为实页号和页内地址。页表包括有效位（装入位）、脏位、引用位、物理页或磁盘地址。**页表长期存储在主存中**。地址映射时同样需要检查有效位。程序不可能总是页面的整数倍，所以最后一页的部分空间会浪费。
2.   快表$TLB$：使用**相联存储器**，所以查找速度更快，也可以使用$SRAM$。在地址转换时，首先查找快表，若命中则无须访问主存中的页表。$TLB$是$Page$的副本（快表是慢表的副本），而$Cache$为主存的副本。快表地址计算与之前的地址计算类似，使用全相联或组相联的模式，映射方式与$Cache$映射类似，若使用组相联也需要留出组号。
     +   每个$TLB$项由页表表项内容加上一个$TLB$标记字段组成，$TLB$标记用来表示该表项取自页表中哪个虚页号对应的页表项。
     +   $TLB$标记的内容在**全相联方式**下就是该页表项对应的**虚页号**；$TLB$标记的内容在**组相联方式**下则是对应**虚页号的高位部分。**
     +   而虚页号的低位部分用于选择$TLB$组的组索引（组号）。
3.   段式虚拟寄存器：虚拟地址分为两部分，段号和段内地址。段表的每一行记录了与某个段对应的段号、装入位、段起点和段长等信息。由于段的长度可变，所以段表中要给出各段的起始地址与段的长度。**段表的段首址加上虚拟地址的段内地址就得到了物理地址**。段长度可变，所以分配空间不便，容易造成碎片问题（外部碎片）。
     +   段式虚拟寄存器的地址变换过程：已调入主存时，从段表读出该段在主存中的起始地址，与段内地址（偏移量）相加，得到对应的主存实地址，同样需要检验有效位（装入位）。
4.   段页式寄存器：把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页。程序对主存的调入、调出仍以**页**为基本传送单位。所以**段长必须是页长的整数倍**，**段首址必须是某页的页首址**。虚拟地址：段号+段内页号+页内地址。
     +   $CPU$​根据虚地址访存时：首先根据段号得到段表地址；然后从段表中取出该段的页表起始地址，与虚地址段内页号合成，得到页表地址；最后从页表中取出实页地址，与页内地址拼接形成主存实地址。
5.   虚拟存储器与$Cache$：
     1.   相同之处：都是为了提高系统性能。都把数据划分为小信息块并作为基本的传递单位，虚存系统的信息块更大。都有地址的映射、替换算法、更新策略等问题。依据程序的局部性原理应用“快速缓存的思想”，将活跃的数据放在相对高速的部件中。
     2.   不同之处：
          1.   $Cache$主要解决系统速度，而虚拟存储器却是为了解决主存容量。
          2.   $Cache$全由硬件实现，是硬件存储器，**对所有程序员透明**；而虚拟存储器由$OS$和硬件共同实现，是逻辑上的存储器，**对系统程序员不透明，但对应用程序员透明**。
          3.   对于不命中性能影响，因为$CPU$的速度约为$Cache$的$10$倍，主存的速度为硬盘的$100$倍以上，因此虚拟存储器系统不命中时对系统性能影响更大。
          4.   $CPU$与$Cache$和主存都建立了直接访问的通路，而辅存与$CPU$没有直接通路。也就是说在$Cache$不命中时主存能和$CPU$直接通信，同时将数据调入$Cache$。而虚拟存储器系统不命中时，只能先由硬盘调入主存，而不能直接和$CPU$通信。

#### 具有$TLB$和$Cache$的多级存储系统

寻址过程：

1.   将逻辑地址转换为物理地址：$CPU$给出逻辑地址，由**内存管理单元**$MMU$算得<虚拟页号，页内偏移量>，进行越界判断无异常后将页号与快表$TLB$中的所有页号进行比较。
     1.   如果找到匹配的页号且有效位为`1`(即命中)，说明要访问的页表项在快表$TLB$中有副本。**若快表命中则访问某个逻辑地址仅需一次访存即可**。
          1.   全相联映射：位数 = 虚拟页号位数
          2.   组相联映射：位数 = 虚拟页号位数 - 组号位数
          3.   都不是，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址最后访问该物理地址对应的内存单元。
     2.   如果未命中即没有找到匹配的页号，则需要访问内存中的页表/慢表，找到对应页表项，得到页面存放的内存块号。**若快表未命中，则访问某个逻辑地址至少需要两次访存**。
          1.   若是多级页表，需先将页目录号分成一级页表页目录号和二级页表页号。先查找一级页表，找到匹配的页号且有效位为`1`则将找到的数据作为起始地址查找二级页表。
          2.   再将内存块号与页内偏移量拼接形成物理地址。
          3.   最后，访问该物理地址对应的内存单元，同时将其存入快表，以便后面可能的再次访问。
          4.   但若快表已满，则必须按照一定的页面置换算法对旧的页表项进行替换。
2.   根据物理地址查找数据：优先访问$Cache$，查找$Cache$时将物理地址拆分为对应的行号/组号并比较标记位和有效位，均命中则直接返回数据，无须访问主存。未命中时访问主存。访问$Cache$时：
     1.   计算块内偏移量：首先确定编址单位，就先把$Cache$块总大小除以这个编址方式得到总地址数，然后用多少个二进制位能表示这个总地址数块内偏移量就有多少位。
     2.   计算$Cache$行数/组数：$Cache$总容量$\div$行长。
     3.   计算$Cache$标记：根据地址映射方式计算。

          1.   全相联映射：主存字块标记$+$字块内地址。
          2.   直接映射：主存字块标记$+Cache$行号$+$字块内地址。其中行号表示一共有多少个$Cache$行。
          3.   组相联映射：主存字块标记$+Cache$组号$+$字块内地址。

---

1.   $CPU$访存过程中存在三种缺失情况：
     1.   $TLB$缺失：要访问的页面的页表项不在$TLB$中，硬件或软件完成处理。
     2.   $Cache$缺失：要访问的主存块不在$Cache$中，硬件完成处理。
     3.   $Page$缺失：要访问的页面不在主存中，软件（操作系统的缺页异常处理程序）完成处理。
2.   缺失组合：$Page$命中时，$TLB$和$Cache$均可能发生命中和缺失的情况，但是**当$Page$缺失时，$TLB$和$Cache$一定也缺失**（$TLB$是$Page$的副本，$TLB$缺失则$Page$也可能缺失，信息不在主存，也一定不在$Cache$）。
     1.   当$Page$、$TLB$、$Cache$均命中时，此时无须访问主存。
     2.   当$Page$命中，$TLB$、$Cache$有一个缺失时，需要访问一次主存。
     3.   当$Page$命中，$TLB$、$Cache$均缺失时，需要访问两次主存。
     4.   当$Page$、$TLB$、$Cache$均缺失时，发生“缺页异常”，需要访问磁盘，并且至少访问两次主存。
