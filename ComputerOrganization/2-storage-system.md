# 第三章 存储系统

## 导读

### 【考纲内容】

1. **存储器的分类**
2. **层次化存储器的基本结构**
3. **半导体随机存取存储器**：$SRAM$、$DRAM$、$Flash$存储器
4. **主存储器**：$DRAM$芯片和内存条、多模块存储器、主存和 $CPU$之间的连接
5. **外部存储器**：磁盘存储器、固态硬盘$SSD$
6. **高速缓冲存储器**
    1. $Cache $的基本原理
    2. $Cache $和主存之间的映射方式
    3. $Cache $中主存块的替换算法;
    4. $Cache $写策略
7. **虚拟存储器**
    1. 虚拟存储器的基本概念
    2. 页式虚拟存储器：基本原理、页表、地址转换、快表$TLB $
    3. 段式虚拟存储器的基本原理
    4. 段页式虚拟存储器的基本原理

### 知识导图

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/672FB81A53104DD5A97665FF62EFF7DB.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/38C568CC236147D58434E3F19E736C23.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/B5A436D1D5A44E8BA040A1327886A3E3.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/A3F555F82C9B4FBCABE43FDEC9208472.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/B62FEAA02C6248DEA9776FB3786C261B.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/F97108E05F724CA28FB4E3B7EB34026B.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/A3F1E19083EF42A2828EDBBFC1D3B6D1.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/24615E5383D14DC39D5F6C66E12B895D.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/B5A2938961C048A68859D0634F7A5FE4.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/B28B6811A1104FE5BFE21B79F0242B34.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/24898425462440FBB9D9C234BE1C05B3.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/E28034CF80874956BC3BCEE9987E86FA.png)

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/CF749DF9747048A9A2AE955907DDFC24.png)

### 【复习提示】

本章是历年命题重点，特别是有关 $Cache $和虚拟存储器的考点容易出综合题。

此外，存储器的特点，存储器的扩展(芯片选择、连接方式、地址范围等)，交叉存储器，$Cache $的相关计算与替换算法，虚拟存储器与快表也容易出选择题。读者应在掌握基本原理的基础上，多结合习题进行反复训练，以加深巩固。

另外，读者需掌握存在 $Cache $和 $TLB $的计算机中的地址翻译与 $Cache$ 映射问题。

在学习本章时，请读者思考以下问题：

1) 存储器的层次结构主要体现在何处? 为何要分这些层次? 计算机如何管理这些层次?

2) 存取周期和存取时间有何区别?

3) 在虚拟存储器中，页面是设置得大一些好还是设置得小一些好?

## 存储器概念

![image-20230830213919636](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302139890.png)

### 存储器的分类

#### 按作用分类

+ 主存储器：主存或内存。
    + 存放计算机运行间的程序和数据。
    + $CPU$、$Cache$，能直接访问。
    + 容量小、速度快、价格高。
+ 辅助存储器：辅存或外存。
    + 存放暂时不用的或永久的数据。
    + 不能与$CPU$直接交换信息。
    + 容量大、速度慢、成本低。
+ 高速缓冲存储器$Cache$。
    + 存放正在执行的程序和数据。
    + 在$CPU$中。
    + 容量小、速度快、价格高。

#### 按存取方式分类

+ 随机存取：**与存储单元的物理位置无关**
    + $RAM(Random\;Access\;Memory)$：随机存取存储器：
        + $DRAM$：动态。
        + $SRAM$：静态。
    + $ROM(Read-Only\;Memory)$：只读存储器。
    + $CAM(Content-Addressable\;Memory)$：相联存储器
+ 串行访问：**读写某个存储单元所需时间与存储单元的物理位置有关**
    + 直接存取$DAM$：磁盘。
    + 顺序存取$SAM$：磁带。

#### 按存储介质分类

+ 磁表面存储器：
    + 磁盘。
    + 磁带。
+ 磁芯存储器。
    + $MOS$型存储器。
    + 双极型存储器。
+ 光存储器：光盘。
+ 半导体存储器。

#### 按信息的可更改性分类

- 读写存储器$(Read/Write\;Memory)$：即可读也可写
    - 如：磁盘、内存、Cache
- 只读存储器$ROM(Read\;Only\;Memory)$：只能读不能写(事实上很多ROM也可以多次读写，只是比较麻烦)
    - 如：实体音乐专辑通常采用$CD-ROM$，实体电影采用蓝光光碟，==$BIOS$通常写在$ROM$中==

#### 按信息可保存性分类

+ 断电后信息是否消失：
    + 易失性：$RAM(Cache，$主存$)$。
    + 非易失性：磁带、$ROM$。
+ 破坏性，存取是否影响存储内存：
    + 破坏性读出：$DRAM$。
    + 非破坏性读出：$SRAM$

### 存储器性能指标

1. 存储容量：存储字数×字长（如$1M\times8$位）。

2. 单位成本：每位价格=总成本÷总容量。

3. 存储速度：数据传输率=数据的宽度(单位$B$)÷存储周期：

    ![image-20230531144914508](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531144914508.png)

    + 存储周期=存取时间+恢复时间。
    + 存取时间（$T_a$）：存取时间是指从启动一次存储器操作到完成该操作所经历平均的时间，分为读出时间和写入时间。
    + 存取周期（$T_m$）：存取周期又称为读写周期或访问周期。它是指存储器进行一次完整的读写操作所需的金部时间，即连续两次独立地访问存储器操作（读或写操作）之间所需的最小时间间隔。

4. 主存带宽（$B_m$）：主存带宽又称数据传输率，表示每秒从主存进出信息的最大数量，单位为字/秒、字节/秒（$B/s$）或位/秒（$b/s$）。

### 存储器层次化结构

![image-20230830214903600](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302149675.png)

+ 结构：$CPU\to Cache\to$主存$\to$辅存$\to$虚拟存储系统。
    1.   在主存和$CPU$之间插入$Cache$是为了解决$CPU$的高速与主存之间的低速速度不匹配的问题，由硬件自动完成
    2.   在虚拟存储系统和主存之间插入辅存是为了解决主存容量不足的问题，由硬件和操作系统共同完成。


+   两个透明
    +   主存和$	Cache$之间的数据调动是由硬件自动完成的，对所有程序员均是透明的
    +   而主存和辅存之间的数据调动则是由硬件和操作系统共同完成的，对应用程序员是透明的
+   两个目的
    +   存储器层次化结构的目的是解决容量、速度和成本的矛盾
    +   引入$Cache$是为了解决$CPU$的高速与主存之间的低速速度不匹配的问题，由硬件自动完成

## 主存储器

![23August28-110200-1693191720-882ed4f7-1a6a-41c1-8dc9-0f6125aca546](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302140375.png)

### 主存储器的基本组成

#### $SRAM$的工作原理

+   通常把存放一个二进制位的物理器件称为存储元，它是存储器的最基本的构件。地址码相同的多个存储元构成一个存储单元。若干存储单元的集合构成存储体。 
+   静态随机存储器$SRAM$的存储元是用==双稳态触发器六晶体管$MOS$==来记忆信息的，因此==即使信息被读出后，它仍保持其原状态而不需要再生（非破坏性读出）。==
+   ==$SRAM$的存取速度快，但集成度低，功耗较大，价格昂贵，一般用于高速缓冲存储器==

#### $DRAM$基本半导体元器件的原理

+ 存储元：由电路控制的单个存储部件。
  
    ![image-20230531151020133](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531151020133.png)
    
    + 规定电容保存电荷时表示二进制的$1$，反之为$0$
    + 当MOS管接通时，在末端检测到电流即表示存储元存储的数据为$1$，反之为$0$
+ 存储单元：由同一个电路控制的一组同时读写的存储部件集合，一般为一行存储元，一行存储元的个数就代表一次存储的字长。
  
    ![image-20230531154319195](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531154319195.png)
    
    + 对红线通上高电压，监测绿线是否有电流则可以判断存储的数据
    + 每一行存储元组成一个存储字，一个存储字的位数等于数据总线宽度等于计算机位数($64$位计算机数据总线宽度为$64$位)
+ 存储体：由多个存储单元构成的，多个电路控制的存储集合。
+ 存储字：存储单元通电后由电信号表示可以读写的一个存储单元信息集合。存储字的位数就是存储字长，单位是$bit$。

#### $DRAM$存储芯片的基本原理

![image-20230531155044312](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531155044312.png)

$n$位地址对应$2^n$个存储单元和译码器输出线

当电流稳定下来后，译码器会根据$MAR$所给地址的字选线(此处为0号字选线)通上高压电流，$MDR$会在数据线(位线)处读出数据

![image-20230531155714441](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531155714441.png)

存储体总容量=存储单元个数$\times$存储字长

此处等于$2^3 \times 8bit =8 \times 1 Byte=8B$

![image-20230531160212237](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531160212237.png)

+ 控制电路

    + 对于$MAR$端和译码器端：电流可能不稳定，当电流稳定下来才打开译码器开关让电流输入译码器

    + 对于$MDR$端：当电流稳定下来后才控制$MDR$输出数据给数据总线

+ 片选线：是整个存储芯片的开关，用来确定哪一个存储芯片被选中，可用于容量扩充

    + 一个存储器可能由多个存储矩阵组成，由片选线控制哪个存储矩阵工作

    + $\overline{CS}$：**芯片选择信号**，选择指定芯片，低电平有效。
    + $\overline{CE}$：**芯片使能信号**，打开指定芯片进行存储，低电平有效。

+ 读写控制线：见图，字面意思

    + 如果是一根就用$\overline{WE}$表示，低电平写，高电平读。如果是$WE$则反之。
    + 如果是两根，则$\overline{OE}$低电平表示允许读，$\overline{WE}$低电平表示允许写。如果是$OE$和$WE$则反之。

+ 存储矩阵：由大量相同位存储单元阵列。

+ 译码驱动：将来自地址总线的地址信号翻译成对应存储单元的选通信号，该信号在读写电路的配合下未完成对被选中的单元的读写操作。

    + 译码器：将$MAR$输入的地址进行译码，选择选中的存储单元地址。
    + 驱动器：根据译码器提供的地址，通过驱动器获取对应存储单元。

总体结构如下图

![image-20230531160920612](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531160920612.png)

![image-20230531154008906](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531154008906.png)

存储芯片通常描述：

<img src="https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531161352914.png" alt="image-20230531161352914" style="zoom:200%;" />

>   若存储器容量为$64K\times 32$位
>
>   则前面的$64K$表示地址总数，后面的M表示每一个地址里面存放的数据的长度（字长）
>
>   前面的$32$位对应地址总线/字扩展法，后面的M对应数据总线/位扩展法
>
>   存储容量=存储单元个数$\times$存储字长，$64K = 2^{16}$，因此PC和MAR为16位，而MDR为 32位，其他寄存器的位数与MDR的相等。

### 随机存储器$RAM$

**$RAM(Random\;Access\;Memory)$芯片——易失性，断电后数据消失**

#### $DRAM$和$SRAM$的区别

$DRAM(Dynamic\;Random\;Access\;Memory)$：动态随机存储器(动态$RAM$)

$SRAM(Static\;Random \;Access\;Memory)$：静态随机存储器(静态$RAM$)

* $DRAM$主要用于主存，$SRAM$主要用于$Cache$
* **核心区别：存储单元不一样.**$DRAM$使用**栅极电容**(见3.1)存储信息，$SRAM$主使用**双稳态触发器**(6个$MOS$管)存储信息

| 类型                  | DRAM                                                         | SRAM                                                         |
| --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储信息              | ==栅极电容==，充电是1，否则为0                               | ==双稳态触发器==，分为0态和1态                               |
| 破坏性读出            | 破坏性<br />读需要连接电容，检测电流变化，电流随着电路连通而溜走<br />写需要给电容充放电 | 非破坏性<br />读只用查看触发器状态<br />写只用改变触发器状态 |
| 需要刷新              | 需要，因为电容上的电荷只能维持$2ms$，刷新由存储器独立完成不需要$CPU$控制 | 不需要，一直供电能保持两种稳定的状态                         |
| 易失/非易失性存储器？ | 易失(断电后信息消失)，$RAM$芯片都是易失性                    | 易失(断电后信息消失)，$RAM$芯片都是易失性                    |
| 访问                  | 没有片选信号，有$RAS$和$CAS$控制对芯片的访问                 | 片选信号对芯片进行访问                                       |
| 送行列地址            | 分两次送，行地址和列地址分开，所以地址线可以复用，**线路引脚数减少一半**，需要一根行通选线和一根列通选线 | 同时送，因为地址分为行地址和列地址一同发送，需要一根片选线   |
| 运行速度              | 慢                                                           | 快                                                           |
| 集成度                | 高，1个或3个逻辑元件构成                                     | 低，6个逻辑元件构成                                          |
| 于$CPU$相连           | 不直接与$CPU$相连，通过$DRAM$控制器与$CPU$链接               | 直接与$CPU$相连，                                            |
| 发热量                | 小                                                           | 大                                                           |
| 存储成本              | 低，常用于主存(现在的主存通常采用$SDRAM$芯片)                | 高，常用于$Cache$                                            |
| 优点                  | 所用元件少，集成度高<br />功耗低，便于大规模集成             | 存取速度很快<br />不需要刷新                                 |
| 缺点                  | 速度慢<br />需要读后再生<br />需要定期刷新                   | 所有元件较多，集成度较低<br />功耗较大<br />制造成本较高     |

<span style="color：orange">注意：</span>$DRAM$地址复用，而$SRAM$不地址复用。（地址线只有原来的一半）

关于引脚，对于容量为$N\times M$位的存储器，其中$N=2^n$为存储单元个数，$M$为存储字长

+   $DRAM$使用地址线复用技术，地址线线路引脚数减少一半
    +   地址线引脚数为$\dfrac{n}{2}$
    +   数据线引脚数为$M$
    +   读写控制线引脚数为$2$
    +   需要一根行通选线和一根列通选线共两根
+   $SRAM$未使用地址线复用技术
    +   地址线引脚数为$n$
    +   数据线引脚数为$M$
    +   读写控制线引脚数为$2$
    +   只需要一根片选线

#### 存储器芯片结构

![image-20230830223938759](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302239860.png)

+ 存储体：由行选择线$X$和列选择线$Y$选择访问单元。
+ 地址译码器：将地址转换为译码输出线上的高电平，以便驱动对应读写电路。
+ $I/O$控制电路：控制选中单元读出写入，并放大信息。
+ 片选控制信号：产生片选控制。
+ 读/写控制信号：输入读或写命令。

#### $DRAM$的刷新

+ 刷新周期：从上一次刷新结束到下一次对整个$DRAM$全部刷新一遍为止，一般为$2ms$。
+ 刷新单元数：==以行为单元，每次刷新一行存储单元。==
    + 如果译码器有$n$位，则可以寻址$2^n$个，也就需要$2^n$与存储单元连接的线路，很难实现。
    + 将地址拆分为行列地址（$DRAM$行、列地址等长）。
    + ==$SRAM$需要$2^n$条地址线，而$DRAM$需要$2^{\frac{n}{2}+1}$根地址线。==
+ 刷新方式：硬件支持，读出一行的信息后重新写入整个行，占用一个读/写周期。
+ 刷新时刻：假设$DRAM$内部结构排列为$128\times128$的形式，读写周期为$0.5\mu s$，所以$2ms$一共$4000$个周期（注意针对刷新问题，读写时间不是重点，即无论是否读写或者读写多少行，都要在固定时间进行刷新所有行）：
    + 集中刷新：
        + 有一段时间专门刷新，但是这时候就无法访问存储器，称为**访存死区**，该段时间为**死时间**。
        + 因为有$128$行，刷新需要$128$个周期的时间。所以一共需要专门刷新$128\times0.5=64\mu s$，则前面正常读写时间为$2000-64=1936\mu s$，读写需要$3872$个周期。
        + ==读写时间不受刷新工作的影响，但是存在死区。==
    + 分散刷新：
        + 每读取完一行数据就刷新一次。
        + 如在每存取周期$1\mu s$中前$0.5\mu s$用于读写，后$0.5\mu s$用于刷新该行。
        + ==没有死区，但是加长了系统存取周期，降低整机速度。==
    + 异步刷新：
        + 隔一段时间刷新一次，一次要刷新所有的行，而如果将刷新设置在不需要访存的译码时间可以加大利用效率。
        + 将刷新周期除以行数，得到两次刷新操作之间的时间间隔$t$，利用逻辑电路每$t$时间产生一次刷新请求。
        + 因为每隔$2ms$要刷新$128$行即$128$次，所以平均每个时间周期为$\dfrac{2ms}{128}=15.6\mu s$，$15.6\mu s$中要读写数据并刷新一次即一行，所以每$15.6\mu s$中有$0.5\mu s$的死时间，其中前$15.6\mu s-0.5\mu s=15.1\mu s$用来读写。
        + 可以==避免使$CPU$连续等待过长的时间，而且减少了刷新次数，从根本上提高了整机的工作效率。==
        + 仅仅是缩短“死时间”，仍存在“死时间”，

#### RAM的读写周期

+ 读周期：
    + 从给出有效地址开始，到读出所选中单元的内容并在外部数据总线上稳定地出现所需的时间，称为读出时间$t_A$
    + 从数据稳定到数据有效之间存在一个时间缝隙，因为数据线上的信号速度是不一样的，所以需要这个缓冲。
    + 地址片选信号$\overline{CS}$必须保持到数据开始稳定输出，$t_{CO}$为片选的保持时间，即发出片选信号的从地址有效到地址失效的时间，在读周期中$\overline{WE}$为高电平。
    + 读周期与读出时间是两个不同的概念，读周期时间$t_{RC}$表示存储芯片进行两次连续读操做时必须间隔的时间，因为里面存在要等待数据稳定才能开始读的等待时间等其他时间，所以必然大于等于读出时间。

![image-20230605102105845](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230605102105845.png)



+ 写周期：
    + 要实现写操作，要求片选信号$\overline{CS}$和写命令信号$\overline{WE}$必须都为低电平。
    + 为使数据总线上的信息能够可靠地写入存储器，要求$\overline{CS}$信号与$\overline{WE}$信号相“与”的宽度至少为$t_{WC}$。
    + 为了保证在地址变化期间不会发生错误写入而破坏存储器的内容，$\overline{WE}$信号在地址变化期间必须为高电平。
    + 为了保证有效数据的可靠写入，地址有效的时间至少应为
        $$
        t_{WC}=t_{AW}+t_W+t_{WR}
        $$
        其中$t_{AW}$和$t_{WR}$为写入前和写入后必须的间隔时间，$t_W$为写入的时间。
    + 为了保证在$\overline{WE}$和$\overline{CS}$变为无效前能把数据可靠地写入，要求写入的数据必须在$t_{DW}$以前在数据总线上已经稳定。

![写周期](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306051022463.png)

### 只读存储器$ROM$

**$ROM(Read-Only\;Memory)$芯片**：

1.   结构简单，所以位密度比可读写存储器的高。
2.   具有非易失性，所以可靠性高。

#### $ROM$的种类

1.   掩模式只读存储器$MROM (Mask\;Read-Only\;Memory)$ ：厂家按照客户需求，在芯片生产过程中直接写入信息，之后任何人**不可重写，只能读出，无法修改**
     + 可靠性高、灵活性差、生产周期长、只适合批量定制
2.   可编程只读存储器$PROM (Programmable\;Read-Only\;Memory)$ ：用户可用专门的$PROM$写入器写入信息，之后无法修改
3.   可擦除可编程只读存储器$EPROM (Erasable\;Programmable\;Read-Only\;Memory)$ ：允许用户写入信息，之后用某种方法擦除数据，**可进行多次重写**。不能取代$RAM$，因为$EPROM$的编程次数有限，且写入时间过长。
     + 光擦除只读存储器$UVEPROM (Ultraviolet\;Rays，$紫外线$)$ ：**擦除所有信息，无法特定擦除**
     + 电擦除只读存储器$EEPROM$(也常记为$E^2PROM$，第一个$E$是$Electrically$)：可用“电擦除”的方式擦除特定的字
4.   闪速存储器$Flash Memory$ ：在$EEPROM $基础上发展而来， 断电后也能保存信息，且**可进行多次快速擦除重写**。**U盘、SD卡就是闪存**。
     + 注意： ==由于闪存需要先擦除再写入，因此闪存的写速度比读速度要慢==
     + 每个存储元只需单个$MOS$管，位密度比$RAM$高

5.   固态硬盘$SSD (Solid \;State \;Drives)$ ：由控制单元+存储单元($Flash $芯片)构成，与闪速存储器的核心区别在于控制单元不一样，但存储介质都类似，**可进行多次快速擦除重写**。$SSD$速度快、功耗低、价格高
     + 目前个人电脑上常用$SSD$取代传统的机械硬盘
     + 手机辅存也使用$Flash $芯片，但相比$SSD$使用的芯片集成度高、功耗低、价格贵
         + 对于手机$RAM$一般指内存，$ROM$一般指辅存

### 多模块存储器和双端口$RAM$

多模块存储器是一种空间并行技术，利用多个结构完全相同的存储模块的并行工作来提高存储器的吞吐率。常用的有单体多字存储器和多体低位交叉存储器

#### 单体多字存储器

由于$CPU$的速度远快于主存，所以同时从主存中拿出多个指令就能让$CPU$等待$I/O$时间变短，充分利用$CPU$资源，提高运行速度，从而提高效率，单体多字存储器以此而实现。

普通存储器是每行为一个存储单元，而对于单体多字存储器来说，每个存储单元存储$m$个字，若总线宽度也为$m$个字，则一次并行就能读出$m$个字。但是只有数据和指令是连续存放在内存的才能这样操作，转移指令无效。

#### 多体并行存储器

每个模块都有相同的容量和存取速度，以及独立的读写控制电路、地址寄存器和数据寄存器。地址分为体号和体内地址两个部分。

对读取数据进行优化。（不是对传输数据）

+ 高位交叉编址的多体存储器：

    + 高位是体号，低位是体内地址。

    + 如图，可以理解成多根内存条，高位(体号)表示访问内存条编号，低位是体内地址

        ![image-20230601093956529](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601093956529.png)

    + 按列，模块里先编址，一个个模块进行分配。

    + ==只是相当于扩容而已，对于速度没有改变。==

    + 若连续取$n$个存储字，每次访问需要$T$的时间，则耗时$nT$。

        ![image-20230601095142536](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601095142536.png)

    + 对于连续访问连续地址时，只能一个个访问周期依次访问

+ 低位交叉编址的多体存储器：

    <!--根据历年408真题的描述，交叉编址方式就是指低位交叉编址。-->

    + 低位是体号，高位是体内地址。

    + 按行，每一个单元先编址，一行行进行分配。

    + ==低位交叉存储器是交叉存放，很好地满足了程序的局部性原理==

    + 如图，可以理解成多根内存条，低位(体号)表示访问内存条编号，高位是体内地址

        ![image-20230601094034088](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601094034088.png)

    + 由于每个存储体都是独立的，所以可以间隔一小段时间就能进行另一个的存储单元的访存而不用等待上一个单元的阶数。

        + 这就要求其模块数必须到达一个值，从而保证能流水线运行而不会卡住。

    + 设模块字长等于数据总线宽度，模块存取一个字的存取周期为$T$，**总线传送周期(存取时间)**为$r$，所以存储器交叉模块数应该大于等于$m=\dfrac{T}{r}$。

        + 这个值被称为**交叉存取度**。

        ![image-20230601095845355](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601095845355.png)

    + 从而启动该模块后能保证经过$m\times r$的时间后再次使用该模块时上次存取操作已经完成。

        ![image-20230601095531755](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601095531755.png)

    + 若连续取$n$个存储字，每次访问需要$T$的时间，启动间隔为$\tau$，则耗时$T+(n-1)\tau$
      
    + ==存储周期=总线周期×模块数==

如高位交叉编址，体号+体内地址：

|  M0  |  M1  |  M2  |  M3  |
| :--: | :--: | :--: | :--: |
| 0000 | 0100 | 1000 | 1100 |
| 0001 | 0101 | 1001 | 1101 |
| 0010 | 0110 | 1010 | 1110 |
| 0011 | 0111 | 1011 | 1111 |

这时按顺序访问就是竖着的。

低位交叉编址，体内地址+体号：

|  M0  |  M1  |  M2  |  M3  |
| :--: | :--: | :--: | :--: |
| 0000 | 0001 | 0010 | 0011 |
| 0100 | 0101 | 0110 | 0111 |
| 1000 | 1001 | 1010 | 1011 |
| 1100 | 1101 | 1110 | 1111 |

此时顺序访问就是横着的，多个存储体可以共同输入输出数据，可以流水线操作。

对于交叉存储器的存取速度：

+ 模块数为$m$，存储周期为$T$，字长为$W$，数据总线宽度为$W$，总线传输周期为$r$，连续存取$n$个字，求交叉存储器的带宽。

    + 有$m$个存储体，存储周期为$T$，字长为$W$，每隔$r$时间启动下一个存储体，连续存取$n$个字，求交叉存储器的存取速率。

+ 连续存取$n$个字耗时为$T+(n-1)r$，但是需要
    $$
    m\geqslant\dfrac{T}{r}
    $$
    为如果模块数过少，则轮流到某一个存储体时这个存储体上一次的处理还没有完成就无法继续工作了。

+ 所以带宽是
    $$
    \dfrac{n\times W}{T+(n-1)r}
    $$
    
+ 当$n$无限大时，带宽趋近于$\dfrac{W}{r}$，而单个存储体的带宽为$\dfrac{W}{T}$。

多端口存储器是对同一个存储体使用多套读写电路实现的，扩大存储容量的难度显然比多体结构的存储器要大，而且不能对多端口存储器的同一个存储单元同时执行多个写入操作，而多体结构的存储器则允许在同一个存储周期对几个存储体执行写入操作。

#### *双端口RAM

左右有两个独立的端口，所以有两对独立的数据线、地址线、控制线可以同时对主存进行操作，如果不是一个位置不会发生异常。

两个端口对同一主存操作有以下$4$种情况：

1. 两个端口不同时对同一地址单元存取数据。
2. 两个端口同时对同一地址单元读出数据。
3. 两个端口同时对同一地址单元写入数据。应产生写入错误
4. 两个端口同时对同一地址单元，一个写入数据，另一个读出数据。应产生读出错误。

所以只用设置一个“忙”的标志位，若$CPU$发现该端口为忙，则等待一段时间再进行访问。

## 主存储器与$CPU$的连接

![image-20230830214125235](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302141284.png)

对$CPU$来讲，系统中所有物理存储器中的存储单元都处在一个统一的逻辑存储器中，这个逻辑存储器的容量大小受到$CPU$寻址能力的限制。如果一个$CPU$的地址总线宽度为$10$，则该$CPU$可以寻址的存储单元为$2^{10}=1024$个，这$1024$个可寻到的存储单元就构成了这个$CPU$的内存地址空间，也叫做逻辑存储器。

所以对于$CPU$而言，它有一个固定的内存地址大小，对应的地址就是个逻辑地址，所以$CPU$读入的数据有限，一次性处理的能力有限；而内存（如内存条）可以扩充，其实际地址就是物理地址，由操作系统给$CPU$的逻辑地址映射物理地址，还包括替换算法等一系列处理方案。

为了获取更多的容量，所以需要对主存容量进行扩展。

### 连接原理

$CPU$与内存通过总线连接。

![image-20230831214106670](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308312141804.png)

+ ==$MDR$和$MAR$虽然为寄存器，但是现在一般集成在$CPU$上。==
+ 数据总线直接连接在$MDR$上，可以写入也可以读出，是双向的。
    + 数据总线的位数与工作频率的乘积正比于数据传输率。
    + 考虑到存储器扩展的需要，MAR应保证能访问到整个**主存地址空间**

+ 地址总线直接连接在$MAR$上，将$CPU$的地址要求交给主存，是单向的。
    + 地址总线的位数决定了可寻址的最大内存空间

+ 控制总线向主存发送控制类型，如读写要求，是单向的。
    + 控制总线（读/写）指出总线周期的类型和本次输入/输出操作完成的时刻


>   对于容量为$N\times M$位的存储器，前面的N表示地址总数，后面的M表示每一个地址里面存放的数据的长度（字长）
>
>   前面的N对应地址总线/字扩展法，后面的M对应数据总线/位扩展法

### 主存容量扩展

为了获取更多的容量，所以需要对主存容量进行扩展。

#### 位扩展法

相当于上面低位交叉编址的多体存储器中每次读取每个内存条的数据。

![image-20230531215407055](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531215407055.png)

* 对于以上的存储器可以看到是$8K\times 1$位的
    * 地址线的连接：对于$8K$，$8K=2^{13}$，则需要$13$根地址线进行传输(此处为$A_0\sim A_{12}$)，直接对应连接即可
    * $WE(Write\;Enable$，写使能信号$)$的连接：$WE$头上没有横线$(\overline{WE})$，表示高电平使能写，直接对应连接即可
    * 数据总线的连接：这里的存储器只有一位，$D_0$对应连接即可
    * $CS$片选信号：$CS$头上没有横线$(\overline{CS})$，表示高电平有效，这里直接接高电压即可

![image-20230531215642206](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531215642206.png)

8片$8K\times 1$位组合成一块$8K\times 8$位的存储器

**【注意】：**

+ $CPU$的数据线数与存储芯片位数不一定相等，用多个存储器件对数据位数进行扩展（一次性输入输出数据数量）。
+ 地址总线和片选线都是并联的，数据总线连接在每一块芯片上。
+ 因为需要拓展位，所以一次性需要处理所有芯片的数据，从而需要对芯片同时进行片选线同步信号，所以所有芯片的$\overline{CS}$都可以连接在一起。
+ 每个芯片各输入输出一部分数据。
+ 芯片地址分配时将每列并联的一组芯片视为同一个地址组

#### 字扩展法

<img src="https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531220749895.png" alt="image-20230531220749895" style="zoom:150%;" />

+ 增加存储器中字的数量（数据的地址大小即能保存的数据的数量），而位数不变。字扩展将芯片的地址线、数据线、读写控制线相应并联，与位扩展法连接方式一样。

+ 但是如果每个芯片同时输入输出输数据则$CPU$无法区分到底是哪个芯片存储的数据，所以不能再将片选线连在一起同时控制。

+ 需要用片选信号区分个芯片地址范围，即将每个芯片的片选线依次连接在$CPU$的地址线接口上，因为不能同时工作，所以片选线信号$CS$或$\overline{CS}$不会同时为$1$或$0$，而片选线的信号连接在$CPU$的地址线接口上就相当于将片选线的信号也作为芯片存储地址。

+ 每个芯片各存储一部分数据。

    ![image-20230831215340072](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308312153187.png)

+ 如图3.13所示，用4片$16K\times8$位的RAM芯片组成64K、8位的存储器。

    + 4片RAM芯片的数据线$D_0\sim D_7$和$\overline{WE}$都分别连在一起。
    + 将$A_{15}A_{14}$用作片选信号
        + $A_{15}A_{14}=00$时，译码器输出端0有效，选中最左边的1号芯片
        + $A_{15}A_{14}=01$时，译码器输出端1有效，选中2号芯片
        + 以此类推（在同一时间内只能有一个芯片被选中）。

    + 各芯片的地址分配如下： 
        + 第 1 片，最低地址：`00 00 0000 0000 0000`；最高地址：`00 11111111111111 `（16 位）
        + 第 2 片，最低地址：`01 00 0000 0000 0000`；最高地址：`01 11111111111111`
        + 第 3 片，最低地址：`10 00 0000 0000 0000`；最高地址：`10 11111111111111`
        + 第 4 片，最低地址：`11 00 0000 0000 0000`；最高地地：`11 11111111111111`

#### 字位同时扩展法

即增加存储字的数量又增加存储字长。各芯片连接地址线的方式相同，但是连接数据线的方式不同，需要通过片选信号$\overline{CS}$或采用译码器设计连接到对应芯片。

![image-20230531221233861](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230531221233861.png)

+ 字扩展法针对数据总线($D_0\sim D_7$)
+ 位拓展法针对多出来的地址总线($A_{14}，A_{15}$)

### 存储芯片片选

CPU要实现对存储单元的访问，首先要选择存储芯片，即进行片选；然后为选中的芯片依地址码选择相应的存储单元，以进行数据的存取，即进行字选。片内的字选通常是由CPU送出的N条低位地址线完成的，地址线直接接到所有存储芯片的地址输入端（N由片内存储容量2'决定）。 片选信号的产生分为线选法和译码片选法

+ 线选法：
    + 当某地址线信息为`0`时，就选中与之对应的存储芯片，只能一位有效。
    
        ![image-20230831220132519](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308312201597.png)
    
    + 优点：不需要地址译码器，线路简单。
    
    + 缺点：地址空间不连续，选片的地址线必须分时为低电平（否则不能工作)，不能充分利用系统的存储器空间，造成地址资源浪费。
    
+ 译码片选法：
    + 由于译码器可以将$n$位映射到$2^n$位，所以通过地址译码芯片产生片选信号。如线选法如果三位编码只能选择三个芯片，而译码片选法三位编码可以选择八个芯片，即三位二进制编码。
    + 优点：地址空间可连续，可以增加逻辑设计。
    + 缺点：电路逻辑复杂。

### 存储器与CPU的连接

1.   合理选择存储芯片
     +   要组成一个主存系统，选择存储芯片是第一步，主要指存储芯片的类型（RAM或ROM）和数量的选择。
     +   通常选用ROM存放系统程序、标准子程序和各类常数，RAM则是为用户编程而设置的。
     +   此外，在考虑芯片数量时，要尽量使连线简单、方便
2.   地址线的连接
     +   存储芯片的容量不同，其地址线数也不同，而CPU的地址线数往往比存储芯片的地址线数要多。
     +   通常==将CPU地址线的低位与存储芯片的地址线相连==，以选择芯片中的某一单元（字选）， 这部分的译码是由芯片的片内逻辑完成的。
     +   ==而CPU地址线的高位则在扩充存储芯片时使用，用来选择存储芯片（片选），这部分译码由外接译码器逻辑完成。==
     +   例如，设CPU地址线为16位，$A_{15}\sim A_0, 1K\times4$位的存储芯片仅有10根地址线，此时可将CPU的低位地址$A_{9}\sim A_0$与存储芯片的地址线$A_{9}\sim A_0$相连
3.   数据线的连接
     +   CPU的数据线数与存储芯片的数据线数不一定相等，在相等时可直接相连
     +   在不等时必须对存储芯片扩位，使其数据位数与CPU的数据线数相等。
4.   读/写命令线的连接
     +   ==CPU读/写命令线一般可直接与存储芯片的读/写控制端相连，通常高电平为读，低电平为写。== 
     +   有些cpu的读/写命令线是分开的（读为$\overline{RD}$，写为$\overline{WE}$，均为低电平有效），此时cpu的读命令线应与存储芯片的允许读控制端相连，而CPU的写命今线则应与存储芯片的允许写控制端相连
5.   片选线的连接
     +   片选线的连接是CPU与存储芯片连接的关键。存储器由许多存储芯片叠加而成，哪一片被选中完全取决于该存储芯片的片选控制$\overline{CS}$是否能接收到来自CPU的片选有效信号。
     +   片选有效信号与CPU的访存控制信号$\overline{MREQ}$（低电平有效）有关，因为只有当CPU要求访存时，才要求选中存储芯片。若CPU访问I/O，则$\overline{MREQ}$为高，表示不要求存储器工作

## 外部存储器

### 磁盘存储器

计算机的外存储器又称为辅助存储器，目前主要使用磁表面存储器。

所谓“磁表面存储”，是指把某些磁性材料薄薄地涂在金属铝或塑料表面上作为载磁体来存储信息。磁盘存储器、磁带存储器和磁鼓存储器均属于磁表面存储器。

![image-20230601102102925](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601102102925.png)

磁表面存储器的优点：

- 存储容量大，位价格低；
- 记录介质可以重复使用：
- 记录信息可以长期保存而不丢失，甚至可以脱机存档：
- 非破坏性读出，读出时不需要再生。

磁表面存储器的鲮点：

- 存取速度慢；
- 机械结构复杂：
- 对工作环境要求较高。

#### 磁盘存储器

磁盘主要看操作系统，操作系统讲的更详细

##### 磁盘设备的组成

![磁盘结构.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/215c28364c67488ca4e0334ab0ca13c6~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

+ 硬盘存储器的组成。硬盘存储器由**磁盘驱动器、磁盘控制器和盘片**组成。
    + 磁盘驱动器。核心部件**是磁头组件**和**盘片组件**，温彻斯特盘是一种可移动磁头固定盘片的硬盘存储器。
    + 磁盘控制器。硬盘存储器和主机的接口，主流的标准有 $IDE$、$SCSI$、$SATA $等。
+ 存储区域。==一块硬盘含有若干记录面，每个记录面划分为若干磁道，而每条磁道又划分为若干扇区，扇区(也称块)是磁盘读写的最小单位==，即==磁盘按块存取。==
    + 磁头数($Heads$)：即记录面数，表示硬盘共有多少个磁头，磁头用于读取/写入盘片上记录面的信息，一个记录面对应一个磁头。
    + 柱面数$(Cylinders)$： 表示硬盘每面盘片上有多少条磁道。在一个盘组中，不同记录面的相同编号(位置)的诸磁道构成一个圆柱面。
    + 扇区数$(Sectors)$： 表示每条磁道上有多少个扇区。
        + 磁盘存储器的最小读写单位为一个扇区，即磁盘按块存取
        + 磁盘扇区中包含数据、地址和校验等信息

##### 磁盘的性能指标

+ 记录密度。 
    + 记录密度是指盘片单位面积上记录的二进制信息量，通常以道密度、位密度和面密度表示。
    + 道密度是沿磁盘半径方向单位长度上的磁道数，位密度是磁道单位长度上能记录的二进制代码位数，面密度是位密度和道密度的乘积。

+ 磁盘的容量。磁盘容量有非格式化容量和格式化容量之分。
    + 非格式化容量是指磁记录表面可利用的磁化单元总数，它由道密度和位密度计算而来，格式化容量是指按照某种特定的记录格式所能存储信息的总量。
    + ==格式化后的容量比非格式化容量要小。==

+ 平均存取时间。平均存取时间由**寻道时间**(磁头移动到目的磁道的时间)、**旋转延迟时间**(磁头定位到要读写扇区的时间) 和**传输时间**(传输数据所花费的时间) 三部分构成。
    + 由于寻道和找扇区的距离远近不一，故寻道时间和旋转延迟时间通常取平均值。
    + **平均存取时间 = 寻道时间 + 旋转延迟时间（磁头定位到所在扇区的时间）+ 传输时间**
    + 旋转延迟时间=磁盘旋转一圈的时间$\div$2
        + 旋转延迟中，最多旋转１圈，最少不用旋转，平均情况下，需要旋转半圈，所以要除 2

+ 数据传输率。磁盘存储器在单位时间内向主机传送数据的字节数，称为数据传率。
    + 假设磁盘转数为$r$转/秒，每条磁道容量为$W$字节，则数据传输率为$D_r=rN$

##### 磁盘地址

![image-20230601142601900](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601142601900.png)

##### 磁盘工作过程

硬盘的主要操作是寻址、读盘、写盘。 每个操作都对应一个控制字，硬盘工作时，第一步是取控制字，第二步是执行控制字。

硬盘属于机械式部件，其读写操作是串行的，不可能在同一时刻既读又写，也不可能在同一时刻读两组数据或写两组数据。

![image-20230601142744200](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601142744200.png)



#### 磁盘阵列

$RAID $(独立冗余磁盘阵列) 是指将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理内上分割交叉存储、并行访问，具有更好的存储性能、可靠性和安全性。

$RAID $的分级如下所示。在 $RAID1\sim RAID5$ 几种方案中，无论何时有磁盘损坏，都可随时拔出受损的磁盘再插入好的磁盘，而数据不会损坏，提升了系统的可靠性。

* $RAID0$： 无冗余和无校验的磁盘阵列。
  
    ![image-20230601143149962](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601143149962.png)
    
    * 无容错能力
* $RAID1$： 镜像磁盘阵列。
  
    ![image-20230601143248539](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601143248539.png)
    
    * 有容错能力，但成本翻倍
* $RAID2$： 采用纠错的海明码的磁盘阵列。
  
    ![image-20230601143417512](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601143417512.png)
* $RAID3$： 位交叉奇偶校验的磁盘阵列。
* $RAID4$： 块交叉奇偶校验的磁盘阵列。
* $RAID5$： 无独立校验的奇偶校验磁盘阵列。

### 固态硬盘$SSD$

![image-20230830214140538](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302141847.png)

![image-20230601144217002](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601144217002.png)

#### 组成

+ 闪存翻译层
    + 闪存翻译层（$Flash \;Translation\; Layer，FTL$）是固态硬盘（$SSD$）中的一项关键技术，它负责管理闪存芯片中的数据存储和访问。由于闪存芯片的特性，$FTL$在逻辑层和物理层之间建立了一个映射关系，使得操作系统和应用程序可以像访问传统硬盘一样访问闪存芯片中的数据。
    + $FTL$的主要功能包括以下几个方面：
        1. 块管理：闪存芯片的最小单位是一个块（$Block$），通常是几十至几百个连续的页（$Page$）组成。FTL负责将逻辑块地址（$LBA，Logical\; Block \;Address$）映射到物理块地址（$PBA，Physical\; Block\; Address$），以管理块的分配和回收。
        2. 垃圾回收：由于闪存芯片的特性，不能直接在已使用的块中进行数据覆写。当需要更新或删除数据时，$FTL$会将新数据写入新的块中，然后标记旧块为无效。垃圾回收算法会定期检查并回收这些无效块，以释放空间供后续写入操作使用。
        3. 写放大和写放大抑制：闪存芯片的写操作需要先擦除整个块，然后再写入数据。由于擦除操作的开销较大，频繁的小写操作会导致写放大现象，降低固态硬盘的性能和寿命。$FTL$通过采用写放大抑制技术，将多个小写操作合并为一个较大的写操作，减少写放大的影响。
        4. 均衡算法：为了延长闪存芯片的寿命，$FTL$会尽可能均衡地使用所有块，避免部分块的擦写次数过多而导致寿命损耗不均。均衡算法会根据块的使用情况和寿命预测，动态调整块的分配策略。
        5. 错误处理和纠错码：闪存芯片在使用过程中可能会出现数据错误或损坏。$FTL$会通过纠错码和错误检测机制，检测和纠正数据错误，确保数据的完整性和可靠性。
+ 存储介质
    + 固态硬盘$（Solid \;State\; Drive，SSD）$的存储介质主要是闪存芯片（$NAND Flash$）。闪存芯片是一种非易失性存储器，使用电子器件来存储数据。
    + 闪存芯片的基本构成单元是存储单元，每个存储单元可以存储多个位的数据。常见的闪存芯片组织结构包括页（$Page$）、块（$Block$）和平面（$Plane$）：
        - 页（$Page$）：闪存芯片中最小的可编程单元是页。页通常是几$KB$大小，常见的大小为$4KB$或$8KB$。数据可以以页为单位进行读取和写入。
        - 块（$Block$）：一组页构成了一个块，通常由几十至几百个连续的页组成。块是闪存芯片的最小擦除单元，即擦除操作需要对整个块进行，而不能只擦除单个页。
        - 平面（$Plane$）：闪存芯片中的块可以组织成多个平面。每个平面可以独立进行操作，使得同时进行读取和写入操作更高效。

#### 与机械硬盘相比的特点

$SSD（Solid\; State \;Drive）$和机械硬盘在存储技术和性能方面有许多不同之处，它们的主要特点如下：

1. 存储介质
    + $SSD$使用闪存芯片作为存储介质，而机械硬盘使用旋转磁盘和机械臂。闪存芯片具有非易失性，即使断电也能保持数据，而机械硬盘需要电源供应才能正常工作。
2. 读写速度
    + $SSD$的读写速度通常比机械硬盘快得多。由于闪存芯片的特性，$SSD$具有较低的访问延迟和更高的随机访问速度，使得数据的读取和写入更加快速和高效。
3. 震动和噪音
    + 由于机械硬盘中有旋转的磁盘和机械臂的运动，机械硬盘会产生震动和噪音。而$SSD$没有移动部件，因此没有震动和噪音，运行更加静音。
4. 耐用性
    + 但是$SSD$的一个"块"被擦除次数过多（重复写同一个块）可能会坏掉，而机械硬盘的扇区不会因为写的次数太多而坏掉
    + 但引入磨损均衡技术后，$SSD$的闪存芯片具有较长的寿命，可以承受更多的写入操作。相比之下，机械硬盘的磁头和磁盘表面容易受到损坏，使用寿命较短。
5. 能耗
    + $SSD$的能耗通常比机械硬盘低。闪存芯片不需要机械臂的移动和磁盘的旋转，因此功耗更低。
6. 尺寸和重量
    + 由于没有机械部件，$SSD$的体积较小、重量较轻，适合在笔记本电脑和便携设备中使用。机械硬盘由于有机械部件，体积较大、重量较重。
7. 价格
    + 相比之下，$SSD$的价格通常更高。虽然$SSD$的价格在逐渐下降，但相同容量的机械硬盘仍然更便宜。

#### 磨损均衡技术

由于闪存芯片在写入操作时的特性，会导致一些闪存块的擦除次数较多，而其他块很少使用，从而导致磨损不均衡。这种磨损不均衡可能会导致某些块提前失效，影响整个存储系统的可靠性和寿命。

为了解决这个问题，磨损均衡技术采取了以下几种方法：

1. 闪存块的循环使用：磨损均衡技术会对闪存块进行循环使用，使得每个块的擦除次数尽量均衡。当一个块被写满后，系统会将其中的数据转移到其他块中，并擦除原块，然后重新分配给下一个需要写入数据的操作。
2. 块迁移：磨损均衡技术会根据块的使用情况和磨损程度，将一些较少使用的块中的数据迁移到更多使用的块中。这样可以减少某些块的擦除次数，从而达到均衡磨损的目的。
3. 块级别的负载均衡：磨损均衡技术会监控闪存块的使用情况，根据块的负载情况进行调度和均衡。例如，将较多写入操作的块和较少写入操作的块进行分散和平衡，使得整个存储系统的磨损更加均衡。
4. 块的磨损预测：磨损均衡技术会对闪存块的使用情况和擦除次数进行监测和预测。通过分析块的磨损情况，可以提前采取措施，如块迁移或更换，以避免块的早期失效。

## 高速缓冲存储器$Cache$

![cache](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308302142480.png)

### 高速缓冲存储器基本概念

#### 局部性原理

+ 时间局部性：程序所访问的数据在相邻时间也可能访问到。
+ 空间局部性：程序所访问的数据的周围数据也可能访问到。

>   高速缓冲技术就是利用局部性原理，把程序中正在使用的部分数据存放在一个高速的、容量较小的$Cache$中，使$CPU$的访存操作大多数针对$Cache$进行，从而提高程序的执行速度

#### 基本工作原理

+   Cache位于存储器层次结构的顶层，通常由SRAM构成，其基本结构如图

![image-20230831235938173](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202308312359316.png)

+   为便于Cache和主存间交换信息，Cache和主存都被划分为相等的块，Cache块又称Cache行，每块由若干字节组成，块的长度称为块长（Cache行长)。
+   由于Cache的容量远小于主存的容量，所以Cache中的块数要远少于主存中的块数，它==仅保存主存中最活跃的若干块的副本。==
    +   因此==Cache按照某种策略，预测CPU在未来一段时间内欲访存的数据，将其装入Cache。==

+   当CPU发出读请求时，若访存地址在Cache中命中，就将此地址转换成Cache地址，直接对Cache进行读操作，与主存无关
    +   ==若Cache不命中，则仍需访问主存，并把此字所在的块一次性地从主存调入Cache==
    +   ==若此时Cache 已满，则需根据某种替换算法，用这个块替换Cache中原来的某块信息。整个过程全部由硬件实现。==
+   值得注意的是，==CPU与Cache之间的数据交换以字为单位，而Cache与主存之间的数据交换则以Cache块为单位。==

#### 高速缓冲存储器地址

+ 主存储器的地址包括主存块号和块内地址，而$Cache$的地址包含缓冲块号和块内地址，两个块内地址都是一样长的且完全相同的。
  
    ![image-20230601162351734](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601162351734.png)
    
+ $Cache$块又称为$Cache$行。长度为块长或$Cache$行长。

+ $Cache$还有一个标记，用来说明$Cache$块与主存块的关系，等于此块在主存中的块号。

#### 工作流程

先访问$Cache$未命中再访问主存型的计算机：

1. $CPU$发出访问地址，从地址总线传输到$Cache$。
2. 通过$Cache$主存地址映射变换结构，将主存地址转换为$Cache$地址，在$Cache$中寻址对应数据。
3. 如果命中就访问$Cache$并取出指令通过数据总线返回$CPU$。
4. 如果不命中，就直接访问主存，取出信息通过数据总线返回$CPU$，并把这个信息存储在$Cache$中。
5. 需要检测$Cache$是否已满，如果不满就直接将新的主存块调入$Cache$进行存储。
6. 若已经满了则通过$Cache$替换结构，执行替换算法腾出空位再调入。

其中$CPU$和$Cache$之间数据交换以**字**为单位，而$Cache$和内存之间数据交换以**块**为单位。

注意： 某些计算机中也采用同时访问 $Cache $和主存的方式， 若 $Cache $命中， 则主存访问终止；否则访问主存并替换 $Cache$。

根据Cache的读、写流程，实现Cache时需解决以下关键问题：

1.   数据查找。如何快速判断数据是否在Cache中。
2.   地址映射。主存块如何存放在Cache中，如何将主存地址转换为Cache地址。
3.   替换策略。Cache满后，使用何种策略对Cache块进行替换或淘汰。
4.   写入策略。如何既保证主存块和Cache块的数据一致性，又尽量提升效率

#### 命中与未命中

+ 命中：主存块调入缓存，主存块与缓存块建立了对应关系，用标记记录与某缓存块建立了对应关系的主存块号。
+ 未命中：主存块未调入缓存，主存块与缓存块未建立对应关系。
+ 命中率$H$：$CPU$欲访问的信息在$Cache$中的比率，设一个程序执行期间，$Cache$的总命中次数为$N_c$，访问主存的总次数为$N_m$​，则命中率
    $$
    H=\dfrac{N_c}{N_c+N_m}
    $$

    + 命中率与$Cache$的容量与块长有关。一般每块可取$4$到$8$个字，块长取一个存取周期内从主存调出的信息长度。

+ 平均访问时间为$t$，$t_c$为访问一次$Cache$所需时间，$H$是命中率，$t_m$为访问一次主存所需时间：
    + 若先访问$Cache$​未命中再访问主存，则
        $$
        t=Ht_c+(1-H)(t_c+t_m)
        $$
    + 若同时访问$Cache$​和主存则
        $$
        t=Ht_c+(1-H)t_m
        $$

+ 访问效率=$Cache$访存时间÷平均访存时间。
+ 相联存储器：并行比较标记，若有标记与当前将要访问的地址的标记相同，且有效位为1（表示当前存储单元存储数据），则命中；若标记不同，则直接替换。

#### 高速缓冲存储器的效率

+ 效率$e$与命中率有关，$e=$访问$Cache$的时间/平均访问时间$\times100\%$。
+ 假如$Cache$和主存是同时被访问的，设$Cache$命中率为$h$，访问$Cache$的时间为$t_c$，访问主存的时间为$t_m$，则
    $$
    e=\dfrac{t_c}{h\times t_c+(1-h)\times t_m}\times100\%
    $$
    当$h=0$时最小为$\dfrac{t_c}{t_m}$，当$h=1$时最大为$1$。

![image-20230901000830496](C:/Users/willi/AppData/Roaming/Typora/typora-user-images/image-20230901000830496.png)

### 地址映射

![image-20230601160138498](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601160138498.png)

+   Cache行中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到Cache地址空间，即把存放在主存中的信息按照某种规则装入Cache。
+   即将主存块调入（复制而非剪切）时应该将其放在哪里。
+   地址以字节为单位。
+   默认都需要一位有效位，有效位指当前块的地址有效 。
+   <span style="color:orange">注意：</span>$Cache$字块标记是指$Cache$有多少行，而不是有多少容量。

![image-20230601163558303](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601163558303.png)

#### 全相联映射

存储方式：

+ 主存中的每一块可以装入Cache中的任何位置，每行的标记用于指出该行取自主存的哪一块
    + 随机选择空位：空位随意放。
+ **更改标记有效位和标记位**：此时不知道$Cache$里的每一个存储单元存的是主存的哪一块数据，所以还需要将主存的主存块号保存到标记项中。
    + 存储因为是乱序存放，所以一定要把整个主存块号都放入标记项中。

![image-20230903105012322](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309031050457.png)

访存过程

+   $CPU$访存过程如图3.19所示。
+   首先根据访存地址前11位（即主存块号）与Cache中所有块的标记进行对比，找到对应的$Cache$行
+   若标记匹配且有效位为1，则访问$Cache$"命中”
    +   此时根据主存地址中低位的块内地址，在对应的$Cache$行中存取信息
+   若不相等或有效位为0，则“不命中”
    +   则$CPU$正常访问主存并从主存中读出该地址所在的信息送到对应$Cache$组的任意一个空闲行中，将有效位置`1`，并设置标记，同时将该地址中的内容送$CPU$

地址组成：

+ 地址=主存字块标记+字块内地址。

![image-20230903105027036](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309031050119.png)

附加位：

+ 因为无法查看$Cache$里面每个存储块是否有数据，所以还需要一个有效位来表示里面是否有数据，将有效位放入标记项中。

特点：

+ 优点：
    + 比较灵活
    + 冲突概率低
    + 空间利用率高
    + 命中率高。
+ 缺点：
    + 标记比较速度慢
    + 实现成本高
        + 常需采用昂贵的按内容寻址的**相联存储器**进行地址映射

#### 直接映射

存储方式：

+ 对号入座，每一个主存块只能存放在唯一一个地方。

    + 若这个位置已有内容，则产生块冲突，原来的块将无条件地被替换出去

    + ==无须使用替换算法==

+ 将主存储体按$Cache$存储体的长度划分为多个区，主存的每个区只能放在$Cache$的指定区域中。类似于模运算，将主存长度对$Cache$长度取模，地址相同余数的内存块放在同一个$Cache$块中。

+ 直接映射的关系可定义为
    $$
    Cache\mathbb{标记=主存块号}  \mod Cache\mathbb{总行数}
    $$

    +   假设Cache共有$2^c$行，主存有$2^m$块
        +   在直接映射方式中，主存的第0块、第$2^c$块、第$2^{c+1}$块只能映射到$Cache$的第0行
        +   而主存的第1块、第$2^c+1$块、第$$2^c+1$$块……只能映射到Cache的第1行
        +   以此类推。
        +   由映射函数可看出，==主存块号的低c位正好是它要装入的$Cache$行号。==
        +   给每个Cache行设置一个长为$t = m- c$的标记($tag$)，当主存某块调入Cache后，就将其块号的高$t$位设置在对应Cache行的标记中，如图3.18(a)所示。

    ![image-20230901001033314](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309010010447.png)

访存过程

+   $CPU$访存过程如图3.18(b)所示。
+   首先根据访存地址中间的c位，找到对应的$Cache$行
+   将对应$Cache$行中的标记和主存地址的高t位标记进行比较
    +   若相等且有效位为1，则访问$Cache$"命中”
        +   此时根据主存地址中低位的块内地址，在对应的$Cache$行中存取信息

    +   若不相等或有效位为0，则“不命中”
        +   此时$CPU$正常访问主存并从主存中读出该地址所在的信息送到对应$Cache$组的任意一个空闲行中，将有效位置`1`，并设置标记，同时将该地址中的内容送$CPU$


地址组成：

+ 地址=主存字块标记+$Cache$字块标记+字块内地址。

    ![image-20230601164955609](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601164955609.png)

+ $Cache$地址=$Cache$字块标记+字块内地址。

+ 主存字块标记为主存容量除以$Cache$容量，表示要用多少位来区分主存地址。

+ $Cache$字块标记，即$Cache$行号的位数为$Cache$的块数的二对数。

+ 字块内地址就是块内地址，位数为每块容量的二对数。

附加位：

+ 这种映射方式==需要一位有效位标识==是否有数据存储。
+ 若发生冲突，不需要替换算法直接替换出去，所以==不需要替换位。==
+ 但是与全相连映射不同的是，因为直接映射是根据模运算来存储的，所以==行与行之间是顺序的关系，主存块号不需要全部存入标记项，把能区分相同模结果的地址前一部分位的数据存入即可。==

特点：

+ 优点：
    + 不需要使用$Cache$字块标记，有效位存储的地址减少。
    + 实现难度降低。

+ 缺点：不够灵活，即使Cache的其他许多地址空着也不能占用。
    + 这使得==直接映射的块冲突概率最高，空间利用率最低。==


如$Cache$一共八行，则主存按八为一个周期存储，则如$Cache$的$0$号地址中一定存入主存块地址模八后余$0$的主存块，即地址都为为`xx...000`，同理$1$号地址存的都是`xx...001`，所以可以保存主存地址减三的前面位数就足够了。这里的$000$和$001$等类似于$Cache$的组号。若$Cache$的行数为$2^n$，主存块号地址为$c$位，则标记项只用保存$c-n$位就可以了。

#### 组相联映射

存储方式：

+ 按号分组，组内随意放，结合了上面二者的优点。
+ 标记项也需要存入能区分数据块的部分地址。
+ 将$Cache$的块分为$Q$个大小相等的组，主存不再按照$Cache$的行数进行模运算分组存入，而用$Cache$组的个数进行模运算，虽然这样能节省的位数变少，但是这样主存的某一块就可以在每一组内随机选一个存储，而不用只能存储在一个块内浪费其他块的空间。
    + 当$Q=1$时变为全相联映射，当$Q= Cache$行数时变为直接映射。

+ 每组有$r$个行，则称为$r$路组相联。
    + ==N路组相联映射方式，实质上就是将N个Cache行合并，内部采用全相联方式，外部采用直接映射方式==
    + 在组相联映射的Cache中，“比较器”用于并行地比较分组中所有Cache行的Tag标记位与欲访问物理地址的Tag标记位
        + 在访问一个物理地址时，要先根据组号定位到某一分组， 然后用物理地址的高t位（Tag标记）与分组中N个Cache行的Tag标记做并行比较（用N个2t位“比较器”实现），若某个Cache行的Tag标记与物理地址的高20位完全一致，则选中该Cache行


组相联映射的关系可以定义为
$$
Cache标记=Cache组号=主存块号\mod Q
$$

+   路数越大，即每组Cache行的数量越大，发生块冲突的概率越低，但相联比较电路也越复杂。 
+   选定适当的数量，可使组相联映射的成本接近直接映射，而性能上仍接近全相联映射。

![image-20230903110338750](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309031103889.png)

访存过程

+   首先根据访存地址中间的组号（或主存块号的后$c$位）找到对应的Cache组
+   将对应Cache组中每个行的标记与主存地址的高位标记进行比较
    +   若有一个相等且有效位为1
        +   则访问Cache命中
        +   此时根据主存地址中的块内地址，在对应Cache行中存取信息
    +   若都不相等或虽相等但有效位为0
        +   则不命中
        +   此时$CPU$正常访问主存并从主存中读出该地址所在的信息送到对应$Cache$组的任意一个空闲行中，将有效位置`1`，并设置标记，同时将该地址中的内容送$CPU$

地址组成：

+ 地址=主存字块标记+$Cache$组号+字块内地址（$Cache$每行长度）。
  
    ![image-20230601165202006](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601165202006.png)
    
+ 一般物理地址的中间部分直接映射为组号。
+ 当$Cache$组地址位数长度变为表示$Cache$行数的二进制位，那么组号和行号一样就变成了直接映射，若组地址位数为$1$全部为一个组，则$Cache$不分组都随机存储即变成了全相连映射。

附加位：

+ 需要一位有效位。

#### 例题

![img](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309031112113.png)

#### 地址映射总结

+   三种映射方式中
    +   直接映射的每个主存块只能映射到Cache中的某一固定行
    +   全相联映射可以映射到所有Cache行
    +   N路组相联映射可以映射到N行。
        +   N路组相联映射方式，实质上就是将N个Cache行合并，内部采用全相联方式，外部采用直接映射方式

当Cache大小、主存块大小一定时，

1.   直接映射的命中率最低，全相联映射的命中率最高。
2.   直接映射的判断开销最小、所需时间最短，全相联映射的判断开销最大、所需时间最长。
3.   直接映射标记所占的额外空间开销最少，全相联映射标记所占的额外空间开销最大。

#### $Cache$标记项

$Cache$的总位数=一个标记项总位数$\times$总标记项数（$Cache$行总数）。每个$Cache$行对应一个标记项，标记项中应包括：

1.   标记字段：需要计算，主存位数$-$字块内位数$-$（$Cache$行数$\mathcal{{\normalsize OR} } $Cache$组$数）。
2.   有效位：一位。
3.   一致性维护位：“脏”位，仅**回写法/写分配法**，若采用**回写法/写分配法**就加一位。
4.   替换算法位控制位：仅最近最久未使用置换算法$LRU$：对于$r$路组相联，替换算法位长度为$log_{2}r$。


标记位长度=主存地址长度（即主存总容量位数而不是$Cache$容量长度）-其他地址长度（块内地址，即$Cache$行的数量的对数；组地址，即多少个组的对数）。

标记的主要计算在于主存块标记长度，即标记位长度，为什么是这个长度？为什么要如此计算？

我们要将主存的内容放到高速缓冲存储器中，所以我们要根据主存的地址找到$Cache$的地址，并能通过$Cache$的地址找到主存的地址。由于$Cache$的数量远小于主存的数量，所以我们使用不同的方式将主存映射到$Cache$中。我们通过替换映射算法能得到一部分主存和$Cache$的映射规则，但是这种规则只能得到不完整的地址信息，那么其他相关地址信息就是通过标记项来给出，通过标记项和$Cache$位置信息就能完整映射$Cache$到每一个主存地址。

因为是主存地址映射，所以我们自然要映射到每一个主存地址，所以主存地址长度是我们的目标，通过地址信息加和得到所有主存地址。由于主存与$Cache$之间的数据交换单位为块，所以只要给定一个$Cache$块在主存中的首地址，那么一个块内的其他数据的地址也是可以推算的，所以这部分的信息可以在地址总线传输过来的块内偏移量中得到，标记位中就可以不要这个信息，所以主存地址长度减去块内地址长度。通过映射方式不同，我们可以得到每一块或每一组$Cache$与主存之间的映射关系，确定映射关系后，地址总线传输块号或者组号，所以这部分内容也是可以减去的，即主存地址长度再减去块号长度或块组号长度。最后的位数就是标记长度，通过标记位能与块号/组号+偏移地址得到主存地址。

如某计算机的主存地址大小为$256MB$，按字节编址，有$8$个$Cache$行，行长$64B$，使用直接映射方式，求标记项长度。首先主存地址大小为$256MB=2^{28}B$，则主存地址总长度为$28$位；然后行长$64B=2^6B$，则块内偏移地址长度为$6$位，所以$28-6=22$，使用直接映射方式，一共$8$行，所以行号位长度为$3$位，所以$22-3=19$，标记位一共$19$位。

### 替换算法

即$Cache$中存储满了如何处理。对于直接映射法来说，固定替换出前一个数据存入此时的数据，所以替换算法只针对全相联映射和组相联映射。

![image-20230601161801818](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601161801818.png)

#### 随机算法

即$RAND$算法：随机地确定替换的$Cache$块。它的实现比较简单，但没有依据程序访问的局部性原理，故可能命中率较低。但是这种方式基本上不会使用。

#### 先进先出置换算法$FIFO$

>   本节笔记大部分来自于操作系统笔记的内存置换算法，请在脑中自动将各图中的内存块替换为Cache块

每次选择淘汰的页面是==最早进入$Cache$块的页面，只考虑进入时间而不考虑访问次数==

实现方法：把调入$Cache$块的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可，队列的最大长度取决于系统为进程分配了多少个$Cache$块。

![image-20230624230639587](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242306673.png)

缺页了$15$次，置换了$12$次，所以缺页率为$15\div20=75\%$.

假如给定一串页面号：$3，2，1，0，3，2，4，3，2，1，0，4$，使用$FIFO$算法进行置换。

![image-20230624230720890](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242307959.png)

会发现分配三个内存块缺页次数为$9$次，而分配四个内存块缺页次数为$10$次.

+ 这种当为进程分配的**物理块数**增大时，缺页次数不减反增的异常现象就是**$Belady$异常**
+ 但是如果物理块尺寸增大一倍而块数不变，则在程序顺序执行时缺页中断次数会减少.
+ $FIFO$算法使用队列实现，是队列类算法
+ 另外，$FIFO$算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问
+ 因此该算法性能差.

#### 最近最久未使用置换算法$LRU$

+   依据程序访问的局部性原理选择近期内长久未访问过的存储行作为替换的行，平均命中率要比$FIFO$要高，是堆栈类算法，是一种局部性策略。

+   $LRU$算法对每行设置一个计数器，$Cache$每命中一次，命中行计数器清$0$，而其他各行计数器均加$1$，需要替换时比较各特定行的计数值，将计数值最大的行换出。

+   ==若被频繁访问的主存块数量>$Cache$行的数量，则有可能发生“抖动”==

![image-20230601161325604](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601161325604.png)

#### *最不经常使用算法$LFU$

+   将一段时间内被访问次数最少的存储行换出。
+   每行也设置一个计数器，新行建立后从$0$开始计数，每访问一次，被访问的行计数器加$1$，需要替换时比较各特定行的计数值，将计数值最小的行换出，是一种全局性策略。
    +   但是这种策略是无法实现的，因为计算机不可能全局考虑后面会出现什么，而只会考虑局部。

+   平均命中率要比$FIFO$的高，是堆栈类算法。

![image-20230601161747424](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/image-20230601161747424.png)

### 写策略

即$Cache$中内容修改后如何让主存于$Cache$修改的保持一致，分为当前命中和当前不命中的情况：

+ 命中：全写法、写回法。
+ 不命中：写分配法、非写分配法。

标记项结构：有效位+脏位+替换控制位+标记位。

#### 回写法$w rite-back$

Cache写命中时

+   当$CPU$对$Cache$写命中时，只修改$Cache$的内容，而不立即写入主存，只有当此块被换出时才写回主存（全部改完了再写回主存）。
+   ==减少了访存次数，但存在数据不一致的隐患==
+   为了减少写回主存的开销，需要在信息位中使用一个类似于有效位的**脏位/修改位**
    +   若修改位为1，则说明对应Cache行中的块==被修改过，替换时需要写回主存==
    +   若修改位为0，则说明对应Cache行中的块==未被修改过，替换时无须写回主存==

#### 全写法/直写策略$write-through$

Cache写命中时

+   当$CPU$对$Cache$写命中时，必须把数据同时写入$Cache$和主存，当某一块需要替换时，不必把这一块写回主存，用新调入的块直接覆盖即可
+   这种方法==实现简单，能随时保持主存数据的正确性==，缺点是增加了访存次数，降低了 Cache的效率

+   由于写$Cache$要远快于写主存，所以一般使用**写缓冲**$Write\;Buffer$暂存写入的数据，但是如果写的速度过快可能会出现饱和溢出。
    +   CPU同时写数据到Cache和写缓冲中，写缓冲再控制将内容写入主存
    +   写缓冲是一个$FIFO$队列，写缓冲可以解决速度不匹配的问题

![image-20230903114529844](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309031145940.png)

##### 写缓冲$Write\;Buffer$

写缓冲本质是$SRAM$实现的先进先出$FIFO$队列，写速度比向主存的写操作块

$CPU$对$Cache$中某地址进行写操作并且命中时

1. 写操作：当处理器执行写操作时，数据被写入$Cache$，并同时被写入写缓冲。
2. 提交到主存储器：写缓冲将数据提交到主存储器的过程通常是异步的，不需要等待主存储器的响应。这意味着处理器可以继续执行后续指令而不需要等待写操作的完成。
3. 主存储器的更新：后续，写缓冲中的数据将被异步地写入主存储器。写缓冲可以利用主存储器的高带宽和并行性，将多个写操作合并成一个更大的写操作，从而提高数据传输的效率。
4. 数据一致性：在全写法中，写缓冲确保数据被及时写入主存储器，从而保证了数据的一致性。这意味着其他处理器或外部设备可以立即访问更新后的数据，而不需要等待主存储器的访问延迟。

#### 写分配法$write-allocate$

Cache写不命中时

加载主存中的块到$Cache$中，然后更新这个$Cache$块，==即写完$Cache$之后再把$Cache$的值覆盖在主存的数据上，所以也需要设置一个脏位。==

一般搭配回写法使用

缺点是每次不命中都需要从主存中读取一块。

#### 非写分配法$not-write-allocate$

Cache写不命中时

只写入主存，不调入$Cache$。

一般搭配全写法使用。

#### 多级Cache

要将指令Cache和数据Cache分开设计，这就有了分离的Cache结构

![image-20230903115105112](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309031151223.png)

使用两级$Cache$，在与$CPU$直接连接的第一层$Cache$使用全写法，在与主存直接连接的第二层$Cache$使用写回法。

+ 离CPU越近的速度越快，容量越小

+ 离CPU越远的速度越慢，容量越大

## 虚拟存储器

$Cache$为了解决主存和$CPU$之间的问题，而虚拟存储器为了解决主存和辅存之间的问题。虚拟存储器包括主存和辅存，将主存和辅存联合在一起统一编址。

+ 是一个逻辑模型。
+ 用户给出一个地址，叫做**虚地址**或**逻辑地址**，虚拟存储器要给出该地址对应的数据。
    + 用户编程允许涉及的地址称为**虚地址**或**逻辑地址**，虚地址对应的存储空间称为**虚拟空间**或**程序空间**

+ 有辅助硬件将虚地址映射到主存中某个单元，==主存单元地址称为**实地址**或**物理地址**==。
    + 虚地址远大于实地址。

+ 基于局部性原理：在程序执行过程中，程序对主存的访问是不均匀的。
+ CPU使用虚地址时，由辅助硬件找出虚地址和实地址之间的对应关系，并判断这个虚地址对应的存储单元内容是否已装入主存。
    + 若已在主存中，则通过地址变换，CPU可直接访问主存指示的实际单元
    + 若不在主存中，则把包含这个字的一页或一段调入主存后再由CPU访问
    + 若主存已满，则采用替换算法置换主存中的交换块（即页面）。 

+ 由操作系统和一部分硬件完成地址映射。
+ 虚拟存储器也采用和Cache类似的技术，将辅存中经常访问的数据副本存放到主存中。
    + 但是==缺页（或段）而访问辅存的代价很大，提高命中率是关键，因此虚拟存储机制采用全相联映射==， 每个虚页面可以存放到对应主存区域的任何一个空闲页位置。
    + 此外，当进行写操作时，==不能每次写操作都同时写回磁盘==，因而，==在处理一致性问题时，采用回写法。==


![image-20230903222837632](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309032228763.png)

具体内存参考操作系统，主要考页式存储，段式非常少。

对于虚拟存储器的三个地址空间：

+ 实地址=主存页号+页内字地址。
+ 虚地址=虚存页号+页内字地址。
+ 辅存地址=磁盘号+盘面号+磁道号+扇区号。

<span style="color:orange">注意：</span>这里地址空间基本上都是用字地址的，即以机器字长为单位进行编址，这是因为虚拟存储器面向程序员，所以以逻辑的每一个字为单位；而上一讲的高速缓冲存储器面向的机器本身，所以经常以字节为单位进行编址。

<span style="color：orange">注意：</span>虚拟系统中，找到的地址后，进行地址映射是靠操作系统完成，在操作系统的书中会更详细讲到。

### 页式虚拟寄存器

#### 页表

+ 虚拟空间与主存空间都被划分成==同样大小==的页，主存的页称为实页，虚存的页称为虚页。
+ 虚页地址分为虚页号和页内地址，实页地址分为实页号和页内地址
    + ==在虚页转换为实页时，页内地址是相同的，唯一要考虑的是虚页号如何转换为实页号。==

+ 做法就是将这种映射关系存在一张表中，这张表就是页表。
    + 页表存储的是实页号和装入位，用来标识虚拟地址是否装入主存地址
    + 页表长期存储在主存中。

+ 页表包括有效位（装入位）、脏位、引用位、物理页或磁盘地址。
    + **有效位**也称**装入位**，用来表示对应页面是否在主存
        + 若为1，则表示该虚拟页已从外存调入主存，此时页表项==存放该页的物理页号==
        + 若为0，则表示没有调入主存，此时页表项可以==存放该页的磁盘地址==。

    + **脏位**也称**修改位**，用来表示页面是否被修改过，虚存机制中采用回写策略，利用脏位可判断替换时是否需要写回磁盘。
    + **引用位**也称**使用位**，用来配合替换策略进行设置，例如是否实现最先调入（FIFO位）或最近最少用（LRU位）策略等。


![image-20230903223517530](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309032235677.png)

+ CPU执行指令时，需要先将虚拟地址转换为主存物理地址。
    + 页表基址寄存器存放进程的页表首地址，然后根据虚拟地址高位部分的虚拟页号找到对应的页表项
        + 若装入位为1，则取出物理页号，和虚拟地址低位部分的页内地址拼接，形成实际物理地址
        + 若装入位为0，则说明缺页， 需要操作系统进行缺页处理。
    + 地址变换的过程如图3.26所示

![image-20230903223835818](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309032238945.png)

+ 优点：长度固定，页表简单，调入方便。
+ 缺点：
    + 程序不可能总是页面的整数倍，所以最后一页的部分空间会浪费
    + 页不是逻辑上独立的实体，所以处理、保护和共享都不及段式虚拟存储器方便

+   对于页表的大小选择需要适度。
    +   页面若很小，虚拟存储器中包含的页面数就会过多，使得页表的体积过大，导致页表本身占据的存储空间过大，同一个程序需要调用更多页表，使操作速度变慢
    +   当页面很大时，虚拟存储器中的页面数会变少，由于主存的容量比虚拟存储器的容量小，主存中的页面数会更少，每次页面装入的时间会变长，每当需要装入新的页面时，速度会变慢。

#### 快表$TLB$

+   由地址转换过程可知，访存时先访问一次主存去查页表，再访问主存才能取得数据。
    +   如果缺页，那么还要进行页面替换、页面修改等，因此==采用虚拟存储机制后，访问主存的次数更多了。==
+   依据程序执行的局部性原理，在一段时间内总是经常访问某些页时，若把这些页对应的页表项存放在高速缓冲器组成的快表$TLB$中，则可以明显提高效率。
    +   相应地把放在主存中的页表称为慢表$Page$
    +   在地址转换时，首先查找快表，若命中，则无须访问主存中的页表。
    +   $TLB$是$Page$的副本（快表是慢表的副本），而$Cache$为主存的副本。
+   使用相联存储器，所以查找速度更快。
    +   也可以使用$SRAM$。
    +   $DRAM$必须不断刷新不适合$TLB$和$Cache$
+   快表地址计算与之前的地址计算类似，==使用全相联或组相联的模式，==映射方式与$Cache$映射类似，==若使用组相联也需要留出组号。==
    +   每个$TLB$项由页表表项内容加上一个$TLB$标记字段组成，$TLB$标记用来表示该表项取自页表中哪个虚页号对应的页表项。
    +   $TLB$标记的内容在==全相联方式==下就是==该页表项对应的虚页号==。
    +   $TLB$标记的内容在==组相联方式==下则是对应==虚页号的高位部分==
    +   而==虚页号的低位部分用于选择$TLB$组的组索引（组号）==。

>   来自操作系统的笔记
>
>   + 快表，又称**相联寄存器**$TLB$，==是一种访问速度比内存快很多的**高速缓冲存储器**==，用来存放最近访问的页表项的副本，以加速地址变换的过程
>       + 与此对应，内存中的页表常称为慢表.
>       + $TLB$和普通$Cache$的区别一一$TLB$中只有最近页表项的副本，而普通$Cache$中可能会有其他各种数据的副本
>   + 由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间.
>   + 因为局部性原理，一般来说快表的命中率可以达到$90\%$以上.
>   + 有的系统支持快表和慢表同时查询，需要注意题上所给条件
>   + 快表的地址变换过程:![image-20230623220657844](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306232206009.png)
>       1. $CPU$给出逻辑地址，由某个硬件算得页号、页内偏移量，进行越界判断无异常后将页号与快表中的所有页号进行比较.
>       2. 如果找到匹配的页号(即命中)，说明要访问的页表项在快表中有副本
>           + 则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址
>           + 最后访问该物理地址对应的内存单元
>           + 因此==若快表命中则访问某个逻辑地址仅需一次访存即可==
>       3. 如果没有找到匹配的页号
>           1. 则需要访问**内存中**的页表，找到对应页表项，得到页面存放的内存块号
>           2. 再将内存块号与页内偏移量拼接形成物理地址
>           3. 最后，访问该物理地址对应的内存单元
>           4. 同时将其存入快表，以便后面可能的再次访问
>           5. 但若快表已满，则必须按照一定的页面置换算法对旧的页表项进行替换
>           6. 因此，==若快表未命中，则访问某个逻辑地址需要两次访存.==

#### 具有TLB和Cache的多级存储系统

![image-20230903225656536](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309032256714.png)

+   图3.27是一个具有TLB和Cache的多级存储系统，其中Cache采用二路组相联方式。
    +   CPU给出一个32位的虚拟地址，TLB采用全相联方式，每一项都有一个比较器，查找时将虚页号与每个TLB标记字段同时进行比较
        +   若有某一项相等且对应有效位为1，则TLB命中，此时可直接通过TLB进行地址转换
        +   若未命中，则TLB缺失，需要访问主存去查页表。
    +   图中所示的是两级页表方式，==虚页号被分成页目录索引和页表索引两部分==，由这两部分得到对应的页表项，从而进行地址转换，并将相应表项调入TLB，==若TLB已满，则还需要采用替换策略==。
    +   完成由虚拟地址到物理地址的转换后，Cache机构根据映射方式将物理地址划分成多个字段
    +   然后根据映射规则找到对应的Cache行或组，将对应Cache行中的标记与物理地址中的高位部分进行比较，若相等且对应有效位为1，则Cache命中，此时根据块内地址取出对应的字送CPU。

+   查找时，快表和慢表也可以同步进行，若快表中有此虚页号，则能很快地找到对应的实页号， 并使慢表的查找作废，从而就能做到虽采用虚拟存储器但访问主存速度几乎没有下降。

    +   在一个具有Cache和TLB的虚拟存储系统中，CPU 一次访存操作可能涉及TLB、页表、Cache、 主存和磁盘的访问，访问过程如下图所示。

    +   $CPU$访存过程中存在三种缺失情况：

        1.   $TLB$缺失：要访问的页面的页表项不在$TLB$中，硬件或软件完成处理。
        2.   $Cache$缺失：要访问的主存块不在$Cache$中，硬件完成处理。
        3.   $Page$缺失：要访问的页面不在主存中，软件（操作系统的缺页异常处理程序）完成处理。

        这三种缺失的可能组合情况如表3.3所示。

![image-20230903230102281](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309032301504.png)

+   最好的情况是第1种组合，此时无须访问主存
    +   第2种和第3种组合都需要访问一次主存；
    +   第4种组合需要访问两次主存
    +   第5种组合发生“缺页异常”，需要访问磁盘，并且至少访问两次主存

### 段式虚拟寄存器

+ 段式虚拟存储器中的段是按程序的逻辑结构划分的，各个段的长度因程序而异。
+ 虚拟地址分为两部分：段号和段内地址。
+ 虚拟地址到实地址之间的变换是由段表来实现的
    + 段表是程序的逻辑段和在主存中存放位置的对照表
    + 段表：每一行记录了与某个段对应的段号、装入位、段起点和段长等信息。
    + 由于段的长度可变，所以段表中要给出各段的起始地址与段的长度。
    + 段表的段首址加上虚拟地址的段内地址就得到了物理地址。

+ CPU根据虚拟地址访存时
    + 首先根据段号与段表基地址拼接成对应的段表行
    + 然后根据该段表行的装入位判断该段是否已调入主存
        + 装入位为“1”，表示该段已调入主存
            + 已调入主存时，从段表读出该段在主存中的起始地址，与段内地址（偏移量）相加，得到对应的主存实地址

        + 装入位为“0”，表示该段不在主存中

    + 段式虚拟存储器的地址变换过程如图3.29所示。


![image-20230903230554636](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309032305750.png)

+ 优点：按逻辑划分，所以利于编译、管理、修改、保护、共享。
+ 缺点：段长度可变，所以分配空间不便，容易造成碎片问题。
    + 外部碎片

### 段页式寄存器

+ 把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页。
+ ==程序对主存的调入、调出仍以**页**为基本传送单位。==
    + 每个程序对应一个段表，每段对应一个页表。

+ 所以==段长必须是页长的整数倍，段首址必须是某页的页首址。==
+ 虚拟地址：段号+段内页号+页内地址。
+ $CPU$根据虚地址访存时
    + 首先根据段号得到段表地址
    + 然后从段表中取出该段的页表起始地址，与虚地址段内页号合成，得到页表地址
    + 最后从页表中取出实页地址，与页内地址拼接形成主存实地址。

+ 优点：兼具页式和段式虚拟存储器的优点，可以按段实现共享和保护
+ 缺点：在地址变换过程中需要两次查表，系统开销较大。

### 虚拟存储器与Cache

#### 相同之处

1.   最终目标都是为了提高系统性能，两者都有容量、速度、价格的梯度。
2.   都把数据划分为小信息块，并作为基本的传递单位，虚存系统的信息块更大。
3.   都有地址的映射、替换算法、更新策略等问题。
4.   依据程序的局部性原理应用“快速缓存的思想”，将活跃的数据放在相对高速的部件中。

#### 不同之处

1. $Cache$主要解决系统速度，而虚拟存储器却是为了解决主存容量。
2. $Cache$全由硬件实现，是硬件存储器，==对所有程序员透明==；而==虚拟存储器由$OS$和硬件共同实现==，是逻辑上的存储器，==对系统程序员不透明，但对应用程序员透明==。
3. 对于不命中性能影响，因为$CPU$的速度约为$Cache$的$10$倍，主存的速度为硬盘的$100$倍以上，因此虚拟存储器系统不命中时对系统性能影响更大。
4. $CPU$与$Cache$和主存都建立了直接访问的通路，而辅存与$CPU$没有直接通路。
    +   也就是说在$Cache$不命中时主存==能和$CPU$直接通信，同时将数据调入$Cache$==
    +   而虚拟存储器系统不命中时，只能先由硬盘调入主存，而==不能直接和$CPU$通信==。

所以高速缓冲存储器连接主存实地址与$Cache$地址，虚拟存储连接主存实地址和虚拟存储逻辑地址，快表连接虚拟存储逻辑地址与快表地址。