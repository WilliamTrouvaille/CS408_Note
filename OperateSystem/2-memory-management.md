# 第三章 内存管理

## 导读

### 【考纲内容】

1. 内存管理基础

    + 内存管理概念
        + 逻辑地址与物理地址空间
        + 地址变换
        + 内存共享
        + 内存保护
        + 内存分配与回收

    + 连续分配管理方式
    + 页式管理
    + 段式管理
    + 段页式管理

2. 虚拟内存管理

    + 虚拟内存基本概念
    + 请求页式管理
    + 页框分配
    + 页置换算法

    + 内存映射文件$(Memory-Mapped \;Files)$ 
    + 虚拟存储器性能的影响因素及改进方式

### 【知识导图】

### 【复习提示】

+   ==内存管理和进程管理是操作系统的核心内容，需要重点复习.==

+   本章围绕分页机制展开
+   通过**分页管理方式**在物理内存大小的基础上**提高内存的利用率**，再进一步引入请求分页管理方式，实现**虚拟内存**，使内存脱离物理大小的限制，从而**提高处理器的利用率**

>   本章(可能)常用就写这了
>
>   获取分结构的地址中的某部分的方法(写出表达式)
>
>   例如对于以下二级列表分别获取其页目录号和页表索引，设整个逻辑地址为LA
>
>   ![image-20230901230025861](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309012300951.png)
>
>   页目录号可表示为`(((unsigned int)(LA))>>22) & 0x3FF`
>
>   页表索引可表示为`(((unsigned int)(LA))>>12) & 0x3FF`
>
>   首先将其右移到边缘(?)，然后按位与n个1，n为所求部分长度
>
>   例如上式中`0x3FF`即为`0011 1111 1111`

## 内存管理基础知识

![image-20230901111645691](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011116805.png)

![image-20230622210440836](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222104921.png)

### 内存概念

+ 内存是用于存放数据的硬件.
    + 程序执行前需要先放到内存中才能被$CPU$处理.
    + 用于缓冲$CPU$和硬盘间的速度矛盾

+ 内存地址从$0$开始，每个地址对应一个存储单元.
+ 存储单元的大小不定:
    + 按**字节**编址，则每个存储单元大小为一个**字节**即$1B$，$8$个二进制位.
    + 按**字**编址，每个存储单元大小为一个**字**，根据计算机的字长确定大小，若字长为$16$位，则一个字大小为$16$个二进制位.
+ **【注意】:**
    + 字$(Word)$：字是计算机中数据处理的基本单元，表示为二进制位$(bit)$的组合
        + 字的长度取决于计算机的体系结构，通常为一个处理器的原生数据宽度
        + 例如，一个字可以是$16$位、$32$位或$64$位长
        + 字的长度决定了处理器一次性能够处理的数据量
        
    + 字长$(Word Length)$：字长指的是计算机系统中字的位数
        + 它表示一个字可以容纳的二进制位数目
        + 例如，一个32位的字长表示一个字可以容纳32个二进制位
        + 字长通常与处理器的体系结构和寄存器的位数相关联.
    
    + 字节$(Byte)$：字节是计算机中存储和传输数据的最小单位
        + 它一定是由$8$个二进制位(即$8$位)组成
        + 字节是计算机内存中数据的基本存储单位，也是计算机系统中常用的数据单位
        + 大部分计算机系统都以字节为基准进行数据的存储和传输.


### 内存管理功能

![image-20230622211153786](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222111874.png)

内存管理$Memory-Management$是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件技术一直在飞速发展，内存容量也在不断增大，但==仍然不可能将所有用户进程和系统所需要的全部程序与数据放入主存==，因此操作系统必须对内存空间进行合理的划分和有效的动态分配。==操作系统对内存的划分和动态分配，就是内存管理的概念。== 

+   内存空间的分配与回收。

    +   由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。
    +   操作系统负责内存空间的分配与回收
        +   即后面的普通内存管理内容.
+   地址转换。

    +   在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致
    +   因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。 
    +   操作系统需要提供某种技术从逻辑上对内存空间进行扩充，并且操作系统需要提供**地址转换**功能，通过内存管理部件$MMU$，负责程序的**逻辑地址**与**物理地址**的转换.

        + 相对地址(逻辑地址)
            + 从$0$号开始，程序员只用知道逻辑地址，可有相同逻辑地址

        + 绝对地址(物理地址)
            + 内存物理单元的集合，是地址转换的最终地址
            + 从逻辑地址到物理地址就是**地址重定位**.
+   内存空间的扩充。

    +   利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。 
    +   详见<a href="#内存空间扩充">内存空间扩充</a>
+   内存共享。

    +   指允许多个进程访问内存的同一部分
    +   例如，多个合作进程可能需要访问同一块数据，因此必须支持对内存共享区域进行受控访问。 
    +   只有只读区域才能共享，这种代码就是**可重入代码**(纯代码)
        +   即允许多个进程同时访问但是不允许任何进程修改的代码
        +   可以复制副本后自己修改.
        +   可重入程序主要是通过共享来使用同一块存储空间的，或通过动态链接的方式将所需的程序段映射到相关进程中去，==其最大的优点是减少了对程序段的调入/调出，因此减少了对换数量。==
+   存储保护。

    +   保证各道作业在各自的存储空间内运行，互不干扰。 在进行具体的内存管理之前，需要了解进程运行的基本原理和要求

    +   操作系统需要提供内存保护功能，保证各进程在各自存储空间内运行，互不干扰，两种方法：

        1.   在$CPU$中设置一对上、下限寄存器，存放进程的上、下限地址
             + 进程的指令要访问某个地址时，$CPU$检查是否越界.

        2.   采用**重定位寄存器**(又称基址寄存器，用于地址相加)和**界地址寄存器**(又称限长寄存器，用于地址比较)进行越界检查

             + 重定位寄存器中存放的是进程的**起始物理地址**

             + 界地址寄存器中存放的是进程的**最大逻辑地址**

### 程序载入过程

![image-20230901112656761](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011126845.png)

+ 程序运行过程:
    1. 编译
        +   由编译程序将用户源代码编译成若干个目标模块
        +   ==编译就是把高级语言翻译为机器语言==
    2. 链接
        +   由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块.
    3. 装入(装载)
        +   由装入程序将装入模块装入内存运行.
    4. 执行.

#### 链接

将独立的逻辑地址合并为完整的逻辑地址:

1. 静态链接
    +   ==在程序运行之前==，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件(装入模块)
    +   之后不再拆开
    +   需要解决两个问题
        1.   修改相对地址，编译后的所有目标模块都是从0开始的相对地址，当链接成一个装入模块时要修改相对地址。
        2.   变换外部调用符号，将每个模块中所用的外部调用符号也都变换为相对地址
2. 装入时动态链接
    +   将各目标模块==**装入**内存时==，==边装入边链接==的链接方式.
    +   其优点是便于修改和更新，便于实现对目标模块的共享。
3. 运行时动态链接
    +   在程序==**执行**中==需要该目标模块时，才对它进行链接
    +   凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到装入模块上
    +   通过硬件转换机制进行转化
    +   其优点是便于修改和更新，便于实现对目标模块的共享.

动态链接与程序逻辑结构有关，所以段式管理有利于动态链接.

#### 装入

将逻辑地址转换为物理地址:

1. 绝对装入：==只适用于单道程序阶段、未产生操作系统==

    + 在==**编译**时==，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码

    + 装入程序按照装入模块中的地址，将程序和数据装入内存
    + 由于程序中的逻辑地址与实际内存地址完全相同，因此==不需对程序和数据的地址进行修改。==
    + 程序中使用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予.
+ 而通常情况下在程序中采用的是符号地址，编译或汇编时再转换为绝对地址
2. 静态重定位/**可重定位装入**：适用于多道批处理操作系统

    + 在多道程序环境下，多个目标模块的起始地址都从$0$开始，程序中使用的地址、数据存放的地址都是相对于起始地址而言的逻**辑地址**，此时应采用**可重定位装入方式**。

    + 可根据内存的当前情况，使用单独的装入程序将装入模块装入到内存的适当位置

    + ==**装入**时==对地址进行“重定位”，将逻辑地址变换为物理地址
        + ==地址变换是在装入时一次性完成的==
        
        + 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业.
        
        + 作业一旦进入内存后，在运行期间就不能再移动，也不能再申请内存空间.
    
3. 动态重定位：适用于现代操作系统

    + 编译、链接后的装入模块的地址都是从$0$开始的
    
    + 装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要**执行**时才进行
        + 因此装入内存后所有的地址依然是逻辑地址，此时需要一个专门的重定位寄存器的支持
        + 采用动态重定位时允许程序在内存中发生移动.
          
        + ==程序在内存中若发生移动，则需要采用动态的装入方式==
            + 可将程序分配到不连续的存储区中
            + 在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存.
            
        + 便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间.
    

![image-20230901113505288](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011135383.png)

### 逻辑地址与物理地址

+   编译后，每个目标模块都从0号单元开始编址，这称为该目标模块的**相对地址/逻辑地址**
    +   当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的**逻辑地址空间/虚拟地址空间**
    +   对于32位系统，逻辑地址空间的范围为$0\sim 2^{32}-1$
    +   进程在运行时，看到和使用的地址都是逻辑地址。
    +   ==用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的。==
    +   ==不同进程可以有相同的逻辑地址==，因为这些相同的逻辑地址可以映射到主存的不同位置
+   **物理地址空间**是指内存中物理单元的集合，它是地址转换的最终地址
    +   进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。
    +   当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为**地址重定位**
+   ==操作系统通过内存管理部件$MMU$将进程使用的逻辑地址转换为物理地址。==
    +   进程使用虚拟内存空间中的地址，操作系统在相关硬件的协助下，将它"转换”成真正的物理地址。
    +   逻辑地址通过**页表**映射到物理内存，页表由操作系统维护并被处理器引用。

### 进程的内存映像

![image-20230901115357283](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011153382.png)

不同于存放在硬盘上的可执行程序文件，当一个程序调入内存运行时，就构成了进程的内存映像。一个进程的内存映像一般有几个要素： 

+   代码段：即程序的二进制代码，代码段是只读的，可以被多个进程共享。 
+   数据段：即程序运行时加工处理的对象，包括全局变量和静态变量。 
+   进程控制块$PCB$：存放在系统区。
    +   操作系统通过$PCB$来控制和管理进程。 
+   堆：用来存放动态分配的变量。
    +   通过调用`malloc`函数动态地向高地址分配空间。 
+   栈：用来实现函数调用。
    +   ==从用户空间的最大地址往低地址方向增长==。 

代码段和数据段在程序调入内存时就指定了大小，而堆和栈不一样。当调用像`malloc`和`free`这样的C标准库函数时，堆可以在运行时动态地扩展和收缩。用户栈在程序运行期间也可以动态地扩展和收缩，每次调用一个函数，栈就会增长；从一个函数返回时，栈就会收缩。

### 内存保护

确保每个进程都有一个单独的内存空间。内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。内存保护可采取两种方法：

1.   在$CPU$中设置一对上、下限寄存器，存放进程的上、下限地址

     + 进程的指令要访问某个地址时，$CPU$检查是否越界.

2. 采用**重定位寄存器**和**界地址寄存器**

    + **重定位寄存器/基址寄存器**中存放的是进程的起始物理地址
        + 重定位寄存器是用来“加”的
        + 逻辑地址加上重定位寄存器中的值就能得到物理地址
    + **界地址寄存器/限长寄存器**中存放的是进程的最大逻辑地址
        + 界地址寄存器是用来“比”的
        + 通过比较界地址寄存器中的值与逻辑地址的值来判断是否越界
    + ==加载重定位寄存器和界地址寄存器时必须使用特权指令，只有操作系统内核才可以加载这两个存储器。==
        + 这种方案允许操作系统内核修改这两个寄存器的值，而不允许用户程序修改

    ![image-20230901120055808](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011200881.png)

### 内存共享

+   指允许多个进程访问内存的同一部分

+   例如，多个合作进程可能需要访问同一块数据，因此必须支持对内存共享区域进行受控访问。 

+   并不是所有的进程内存空间都适合共享，只有只读区域才能共享，即**可重入代码/纯代码**

    +   即允许多个进程同时访问但是不允许任何进程修改的代码
    +   省流版：==可以复制副本后自己修改==
        +   但在实际执行时，也可以为每个进程配以局部数据区，把在执行中可能改变的部分复制到该数据区
        +   这样，程序在执行时只需对该私有数据区中的内存进行修改，并不去改变共享的代码

+   减少了对程序段的调入/调出，因此减少了对换数量.

+   对于分段系统，由于是以段为分配单位的，不管该段有多大，都只需为该段设置一个段表项，段的共享非常简单易行

    +   太长不看：

        ![image-20230901120703842](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011207989.png)

### 内存分配与回收

+   由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。
+   操作系统负责内存空间的分配与回收
    +   即后面的普通内存管理内容
+   存储管理方式随着操作系统的发展而发展
    +   在操作系统由单道向多道发展时，存储管理方式便由**单一连续分配**发展为**固定分区分配**
    +   为了能更好地适应不同大小的程序要求，又从固定分区分配发展到**动态分区分配**
    +   为了更好地提高内存的利用率，进而从连续分配方式发展到离散分配方式，即**页式存储管理**
    +   为了满足用户在编程和使用方面的要求，引入**分段存储管理**

### <a id='内存空间扩充'>内存空间扩充</a>/覆盖与交换*

![image-20230622213216998](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222132089.png)

内存空间的扩充(用容量小的内存运行大的程序)有三种技术:

1. 覆盖技术.
2. 交换技术.
3. 虚拟存储技术.使用覆盖和交换可以实现虚拟存储.

交换技术主要在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。对于主存无法存放用户程序的矛盾，现代操作系统是通过**虚拟内存技术**来解决的

覆盖和交换技术本质是通过不断换入换出数据，以时间换空间，所以对外存对换区的管理应该以提高交换速度减少交换时间为目标.

覆盖技术则已成为历史，而交换技术在现代操作系统中仍具有较强的生命力

#### 覆盖

+   早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。 
+   覆盖的基本思想如下：
    +   由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序）
    +   因此可把用户空间分成一个固定区和若干覆盖区。
    +   将经常活跃的部分放在固定区，其余部分按调用关系分段
    +   首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。
+    覆盖技术的特点
    +   打破了必须将一个进程的全部信息装入主存后才能运行的限制
    +   但当同时运行程序的代码量大于主存时仍不能运行
    +   此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存
    +   ==覆盖技术对用户和程序员不透明==

#### 交换

+   **交换/对换**的基本思想
    +   把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称换出；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称换入
    +   第2章介绍的**中级调度**采用的就是交换技术。 
        +   抽问：高级调度，中级调度，低级调度分别是什么
+   有关交换，需要注意以下几个问题
    +   交换需要备份存储，通常是磁盘。它必须足够大，并提供对这些内存映像的直接访问。
    +   为了有效使用CPU，需要使每个进程的执行时间比交换时间长。
    +   若换出进程，则必须确保该进程完全处于空闲状态。
    +   交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用起来可能很快。
    +   交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时就暂停。 
    +   普通的交换使用不多，但交换策略的某些变体在许多系统（如UNIX）中仍发挥作用。 

## 普通内存管理

![内存管理方式](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011117726.png)

![image-20230622221001841](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222210928.png)

内存空间的分配分为:

+ 连续分配管理：
    + 单一连续分配.
    + 固定分区分配.
    + 动态分区分配.
+ 非连续分配管理/离散分配方式：
    + 基本分页存储管理.
    + 基本分段存储管理.
    + 段页式存储管理.

连续分配是指为用户进程分配的必须是一个连续的内存空间，而非连续分配反之.

**【注意】:**

+ **内部碎片**，是==已经被分配出去==却不能被利用的内存空间.
    + ==能明确指出属于哪个进程==

+ **外部碎片**，是==还没有被分配出去==，但由于太小了无法分配给申请内存空间的新进程的内存空闲区域.
    + ==不属于任何进程==
    + 可以通过**紧凑/拼接**技术来移动进程位置合并空闲空间.

>   存储管理方式随着操作系统的发展而发展
>
>   +   在操作系统由单道向多道发展时，存储管理方式便由**单一连续分配**发展为**固定分区分配**
>   +   为了能更好地适应不同大小的程序要求，又从固定分区分配发展到**动态分区分配**
>   +   为了更好地提高内存的利用率，进而从连续分配方式发展到离散分配方式，即**页式存储管理**
>   +   为了满足用户在编程和使用方面的要求，引入**分段存储管理**


### 单一连续分配

+ 内存被分为系统区和用户区
    + ==系统区通常位于内存的低地址部分==，用于存放操作系统相关数据
    + 用户区用于存放用户进程相关数据.

+ 内存中只能有一道用户程序，用户程序独占整个用户区空间.
+ 优点:
    + 实现简单.
    + ==无外部碎片==
    + 可以采用覆盖技术扩充内存.
    + 因为只有一道程序，所以肯定不会访问越界，不一定需要采取内存保护
        + 如早期的$PC$操作系统$Ms-Dos$
+ 缺点:
    + 只能用于单用户、单任务的操作系统中.
    + ==有内部碎片==
    + 存储器利用率极低.

### 固定分区分配

+ 将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业

    + 当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区，如此循环

+ 分区的方式
    + 分区大小相等
        + 缺乏灵活性
            + 程序太小会造成浪费，程序太大又无法装入
        + 但是很适合用于用一台计算机控制多个相同对象的场合.
    + 分区大小不等
        + 增加了灵活性，可以满足不同大小的进程需求
        + 根据常在系统中运行的作业大小情况进行划分
            + 比如划分多个小分区、适量中等分区、少量大分区

+ 记录分区的方法
    + 操作系统需要建立一个数据结构——**分区说明表**来实现各个分区的分配与回收

        ![image-20230901122135697](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011221800.png)

    + 每个表项对应一个分区，通常按分区大小排列

    + 每个表项包括对应分区的大小、起始地址、状态(是否已分配)

+ 分区分配过程
    + 当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表
    + 从中找到一个能满足大小的、未分配的分区，将之分配给该程序，然后修改状态为“己分配”.

+ 优点:
    + 实现简单.
    + ==无外部碎片==

+ 缺点:
    + 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能.
    + ==会产生内部碎片==，内存利用率低.
        + 当程序小于固定分区大小时，也要占用一个完整的内存分区，这样分区内部就存在空间浪费即产生内部碎片

### 动态分区分配

+ 动态分区分配又称为**可变分区分配**
    + 这种分配方式不会预先划分内存分区
    + 而是在进程==装入内存时==，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要
    + 因此==系统分区的大小和数目是可变的==
    + 动态分区随着时间的推移会产生越来越多小的内存块，内存的利用率随之下降
        + ==产生外部碎片==
        + 克服外部碎片可以通过**紧凑**技术来解决，即操作系统不时地对进程进行移动和整理。
        + 但这需要**动态重定位寄存器**的支持，且相对费时。
            + 紧凑的过程实际上类似于Windows系统中的磁盘碎片整理程序，只不过后者是对外存空间的紧凑。
    
+ 记录分区的方法(使用的数据结构)
    + 空闲分区表
        + 每空闲分区对应表项
        
        + 表项中包含分区号、分区大小、分区起始地址、分区状态等信息
        
            ![image-20230622214735443](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222147487.png)
        
        + **【注意】:**
            + 各表项的顺序不一定按照地址递增顺序排列，具体的排列方式需要依据**动态分区分配算法**来确定
        
    + 空闲分区链
        + 每个分区的起始部分和末尾部分分别设置前向指针和后向指针
        
        + 起始部分处还可记录分区大小等信息.
        
            ![image-20230622214742894](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222147936.png)
    
+ 动态分区分配：解决`当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配`的问题
    + 把一个新作业装入内存时，须按照一定的**动态分区分配算法**，从空闲分区表(或空闲分区链)中**选出一个分区**分配给该作业
    + 由于分配算法算法对系统性能有很大的影响，因此人们对它进行了广泛的研究.
    + 见下节<a href="#动态分区分配算法">动态分区分配算法</a>
    
+ 分配分区后修改数据结构
    + 把一个新作业装入内存时，在**按照某种分配算法已经分配好分区后**修改相应的记录分区的数据结构
    + 以使用空闲分区表为例
        + 当选择的分区分区大小大于分配空间，则分区大小相减，并修改起始地址
        + 当选择的分区分区大小等于分配空间，则删除该表项.

+ 回收分区
    + 若回收区的后面或前面有一个相邻的空闲分区则两个表项合并为一个.
    + 若回收区的后面和前面都有一个相邻的空闲分区则三个表项合并为一个.
    + 若回收区的后面或前面都没有一个相邻的空闲分区，则新增一个表项.
    
+ 动态分区和固定分区分配方式相比，内存空间的利用率要高一些。

    + 但是总会存在一些分散的较小空闲分区，即外部碎片，它们存在于已分配的分区之间，不能充分利用。

    + 可以采用**拼接**技术加以解决。

    + ==固定分区分配方式存在内部碎片，而无外部碎片==

    + ==动态分区分配方式存在外部碎片， 无内部碎片==


### 动态分区分配算法

![image-20230622225651797](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222256882.png)

为了解决动态分区分配方式中如何从多个空闲分区中选择一个分区分配

#### 首次适应算法$First\;Fit$

+ 算法思想
    + 每次都从低地址开始查找，找到第一个能满足大小的空闲分区.

+ 如何实现
    + 空闲分区以==地址递增==的次序排列
    + 每次分配内存时顺序查找空闲分区链(或空闲分区表)
    + 找到大小能满足要求的第一个空闲分区

+ 优点
    + 首次适应算法每次都要从头查找，每次都需要检索低地址的小分区
    + 但是这种规则也决定了当低地址部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也会更有可能把高地址部分的大分区保留下来
    + 算法开销小，每次分区后不需要对分区队列重新排序
+ 缺点
    + 造成低分区大量内存碎片
    + 都要重复经过已经分配的底层区间，增加查找开销

#### 最佳适应算法$Best\;Fit$

+ 算法思想
    + 由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域
    + 因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区
        + 即优**先使用更小的空闲区**.
+ 如何实现
    + 空闲分区按==容量 递增次序==链接
        + 递增次序:从小到大

    + 每次分配内存时顺序查找空闲分区链(或空闲分区表)
    + 找到大小能满足要求的第一个空闲分区
    + 当分配完后需要重新调整空闲分区链(或空闲分区表).
+ 优点:容易保存大分区.
+ 缺点:
    + 最佳适应算法虽然称为"最佳”，但是性能通常很差
        + 因为每次最佳的分配会留下很小的难以利用的内存块，会==产生最多的外部碎片且很难查找回收.==
    + 算法开销大，==每次分区外需要对分区队列进程重新排序==

#### 最坏适应算法$Worst\;Fit$

+ 算法思想
    + 为了解决最佳适应算法的问题――即留下太多难以利用的小碎片
    + 可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用.
        + 即优**先使用更大的空闲区**.

+ 如何实现
    + 空闲分区按==容量 递减次序==链接
        + 递减次序:从大到小

    + 每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区
        + 由于是从大到小排列，一般每次都是选取最大的分区进行分配

    + 当分配完后需要重新调整空闲分区链(或空闲分区表).

+ 优点:可用减少难以利用的小碎片.
+ 缺点:
    + 每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大更可用，但是这种方式会导致较大的连续空闲区被迅速用完，因此性能也非常差
        + 如果之后有“大进程”到达，就没有内存分区可用了.
    + 算法开销大，==每次分区外需要对分区队列进程重新排序.==

#### 临近适应算法$Next\;Fit$

+ 算法思想
    + 首次适应算法每次都从链头开始查找的
    + 这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区
    + 因此也增加了查找的开销
    + 如果每次都**从上次查找结束的位置**开始检索，就能解决上述问题.

+ 如何实现
    + 空闲分区以==地址 递增==的顺序排列(可排成一个循环链表)
        + 递增:从小到大

    + 每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)
    + 找到大小能满足要求的第一个空闲分区.

+ 优点:减少了检索空闲分区的次数，提高了效率，算法开销小
+ 缺点:邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用.

所以综合效果来看，首次适应算法>最佳适应法?临近适应法>最大适应法.

首次适应法和临近适应法只用简单查找，最佳适应法和最大适应法都需要对可用块进行排序和遍历.

### 基本分页存储管理

![image-20230622235206918](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222352013.png)

#### 分页

+ 页框和页框号
    + 将**内存空间**分为一个个大小相等的分区，每个分区就是一个“页框”$Page\;Frame$，或称“页帧”、“内存块”、“物理块”
        + ==页框=页帧=内存块=物理块=物理页面==

    + 每个页框有一个编号，即“页框号”(或者“内存块号”、“页帧号”、“物理块号”)
        + 页框号从$0$开始.
        + ==页框号=页帧号=内存块号=物理块号=物理页面号==
    
    + 页框不能太大，否则可能产生过大的内部碎片
    
    + 页框不能太小，否则会导致页面数过大，页表过长占用内存，同时增加硬件地址转换的开销，降低页面换入换出的效率.
    
+ 页和页号
    + 将**用户进程的地址空间**也分为**与页框大小相等**的一个个区域，称为“页”($Page$)或“页面”.

    + 每个页面也有一个编号，即“页号”，页号也是从$0$开始

    + 所以==页面不同于页框，是进程的逻辑概念==
        + 进程的最后一个页面可能没有一个页框那么大
    
+ 操作系统以页框为单位为各个进程分配内存空间
    + 进程的每个页面分别放入一个页框中
    + 也就是说，==进程的页面与内存的页框有**一一对应**的关系.==

+ 外存中也==同样的单位==进行划分，直接称为“块”($Block$).
+ ==各个页面不必连续存放，也不必按先后顺序来，可以放到不相邻的各个页框中.==
+ 为了方便计算页号、页内偏移量、页面大小一般设为$2$的整数幂.
+ 如果每个页面大小为$2^kB$，用二进制数表示逻辑地址，则末尾$k$位即为页内偏移量，其余部外就是页号.
+ ==由于是对程序根据内存大小进行分页，所以只对硬件和操作系统是可见的，对于连接装配程序、编译系统、用户都是透明的.==

#### 地址结构

+ 分为页面偏移量$W$和页号$P$两个部分.

    ![image-20230901144159952](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011442038.png)

+ 以32位计算机为例，地址长度为$32$位，$0\sim11$是页内地址，即**页内偏移量**，每页大小为$4KB$.
    + 如果有$K$位表示“页内偏移量”，则说明该系统中一个页面的大小是$2^K$个内存单元

+ $12\sim31$为**页号**，代表每个进程内的页的顺序，地址空间最多允许$2^{20}$页.
    + 如果有$M$位表示“页号”，则说明在该系统中，一个进程最多允许有$2^M$个页面

+ **【重要考点】:**
    + ==页面大小$\rightleftharpoons $页内偏移量位数$\longrightarrow  $逻辑地址结构==


#### 页表

+ 为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，它记录页面在内存中对应的物理块号，页表一般存放在内存中。
  
+ 操作系统要为每个进程建立一张页表，其中页表大小也与页面一样被页框约束.
  
    + 进程的各个页能被**离散**的存储在内存不同的物理块
    + 在进行进程切换时，需要切换页表，即将新进程的页表加载到内存中，并将处理器的页表指针指向新的页表
    + 页表是记录逻辑空间（虚拟内存）中每一页在内存中对应的物理块号。但并非每一页逻辑空间都会实际对应着一个物理块，只有实际驻留在物理内存空间中的页才会对应着物理块。
    
+ 页表是需要一直驻留在物理内存中的（多级页表除外），另外页表的起址和长度存放在$PCB$进程控制结构体中。

+ 当进程未执行，则页表始址和页表长度在其$PCB$中，执行时将其装入$PTR$(页表始址寄存器)中从而进驻内存.

+ 页表组成
    1. 一个进程对应一张页表和一个逻辑地址
    
    2. 进程的每一页对应一个页表项
    
    3. 每个**页表项**由“页号”和“块号”组成
        + 页表项连续存放，因此==页号可以是隐含的，**不占存储空间**==
    
            + 类比数组
        + 块号的求法:参考以下例题
            1. 物理内存大小除以页面大小得到内存块号表示位数
                + 单位是$bit$
            2. $bit$除以$8$换算成字节得到页表项中块号至少占多少字节
        + **【注意】:**
            + **页表记录的只是内存块号，而不是内存块的起始地址！**
            + $J$号内存块的起始地址=$J\times$内存块大小
                + 页框号(内存块号)从$0$开始
                
            + >   页表项与地址结构是不同的两个概念
                >
                >   页表项与地址都由两部分构成，而且第一部分都是页号，但页表项的第二部分是物理内存中的块号，而地址的第二部分是页内偏移；==页表项的第二部分与地址的第二部分共同组成物理地址。==
                >
                >   1. **页表项（Page Table Entry）**：
                >
                >      - **定义**：页表项是一个数据结构，通常存储在操作系统管理的页表中。每个页表项对应一个虚拟内存页（或页面）与物理内存页的映射关系。
                >      
                >      - **作用**：页表项用于跟踪虚拟内存页与物理内存页之间的映射关系，以实现虚拟内存的分页机制。每个页表项存储了虚拟页号（通常是一组高位地址）到物理页号（一组低位地址）的映射。
                >      
                >      - **结构**：页表项通常包括虚拟页号、物理页号以及一些控制位，如有效位（表示映射是否有效）、读写权限位等。
                >
                >      - **数量**：每个进程都有一个页表，其中包含多个页表项，数量取决于虚拟地址空间的大小和页面的大小。
                >
                >   2. **分页存储的地址结构**：
                >
                >      - **定义**：分页存储的地址结构是指虚拟地址和物理地址之间的映射关系。这种映射关系通过页表来实现，页表负责将虚拟地址翻译为物理地址。
                >      
                >      - **作用**：分页存储的地址结构定义了如何将虚拟地址空间中的地址映射到物理内存中的地址，以支持虚拟内存管理和进程间的隔离。
                >      
                >      - **结构**：分页存储的地址结构包括虚拟地址和物理地址。虚拟地址通常分为页号和页内偏移两部分，而物理地址也分为页号和页内偏移。页号用于索引页表，将虚拟页号映射到物理页号。
                >
                >      - **数量**：分页存储的地址结构的数量取决于虚拟地址空间和物理内存的大小，以及页面的大小。每个虚拟地址都需要经过地址翻译才能找到对应的物理地址。
                >
    
    4. 页表记录进程**页面**和实际存放的**内存块**之间的映射关系.
    
    5. 每个页表项的长度是相同的
    
        ![image-20230901144337587](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011443678.png)

>   假设某系统物理内存大小为$4GB$，页面大小为$4KB$，则每个页表项至少应该为多少字节？
>
>   + 首先$4GB=2^{32}B$，$4KB=2^{12}B$.
>   + 因此$4GB$的内存总共会被分为$2^{32}\div2^{12}= 2^{20}$个内存块，因此内存块号的范围应该是$0\sim2^{20}-1$，因此至少要$20bit$($20$个二进制位)才能表示这么多的内存块号
>       + 因此至少要$3$个字节才够，因为每个字节$8$位，$3\times8=24>20$.
>
>   + 所以至少需要$3B$来表示块号.
>       + **【注意】:重要重要重要重要考点**
>           + ==计算机中内存块的数量$\to$页表项中块号至少占多少字节==
>
>   + 由于页号是隐含的，因此每个页表项占$3B$
>   + 深入来看
>       + 因为每页表项会顺序连续存储在内存中，若该页表在内存中存放的起始地址是$X$
>       + 则$M$号页对应的页表项存放在内存地址$X+3\times M$.
>           + 3表示需要$3B$来表示块号.
>       + 同时因为页面大小为$4KB$，所以每个页框(即可用存放的最大值)大小为$4\times1024\div3=1365$个页表项
>       + 但是此时每页会余下$4\times1024\mod3=1$页内碎片，所以一定会在中间空出内存
>       + 所以$1365$号页在页框约束下会在新的下一个页框存储，表项会存放在$X+3\times1365+1$处
>           + 这时候地址公式就不管用了.
>
>       + 而如果每个页表项占$4$字节，则每个页框刚好能放下$1024$个页表项，从而没有余数，能减少查找的麻烦.
>
>   + 所以理论上$3B$就能表示内存块的范围，但是为了方便页表查找(对齐)，实际上会多一些字节，使得每个页面能装下整数个页表项.
>       + 如取成4B，这样一页正好可以装下1K个页表项，或增加一些其他信息
>

#### 页式基本地址变换机构

![image-20230623221239986](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306232212052.png)

+ 每个页面的特点
    + 虽然进程的各个页面是离散存放的，但是页面内部是连续存放的

+ 可用借助页表进行转换，通常会在系统中设置**一个**页表寄存器$PTR$，存放页表在内存中的起始地址$F$和页表长度$M$(页表长度即这个进程里有多少页)
+ ==进程未执行时，页表的始址和页表长度放在进程控制块$PCB$中，当进程被调度时，操作系统内核会把它们放到页表寄存器中.==
+ 在页式存储管理的系统中时，只用确定页面大小和逻辑结构就能得到物理地址.

![image-20230901150815443](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011508531.png)

基本地址变换机构需要先查询页表，再查询内存两次操作:

1. 要算出逻辑地址$A$对应的页号$P$与页内偏移量$W$.
    + 页号$P$=逻辑地址$A\div$页面长度$L$
    + 页内偏移量$W$=$A$逻辑地址$\%$页面长度$L$
2. 检测页号$P$是否越界
    +   如果页号$P$大于等于页表长度$M$，则内中断
        +   因为页号从$0$开始，页表长度至少为$1$，从而$P=M$时页会越界
        +   页号$P$范围$0\sim M-1$
3. 根据页表中页号$P$求页表寄存器中的页表项地址$PA$=页表起始地址$F$+页号$P\times$页表项长度$PL$，得到页表中对应的页表项，从而确定页面存放的内存块号$B$
    + 页表长度指的是这个页表中总共有几个页表项，即总共有几个页.
    + 页表项长度$PL$指的是每个页表顶占多大的存储空间.
    + 页面大小指的是一个页面占多大的存储空间.
4. 最后物理地址$E$=内存块号$B$×页面大小$L$+页内偏移量$W$
    + 如果页面大小是$2$的整数次幂，则转换二进制直接拼接起来就是最终物理地址了

>   **【例题】:**
>
>   + 在某计算机系统中，页面大小是$50B$，某进程逻辑地址空间大小为$200B$，则逻辑地址`110`对应的页号、页内偏移量是多少？
>
>   **【解答】:**
>
>   ![image-20230622234130894](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306222341944.png)
>
>   + 页号$=110/50=2$
>   + 页内偏移量$=110\%50=10$

#### 具有快表的地址变换机构

+ 快表，又称**相联寄存器**$TLB$，==是一种访问速度比内存快很多的**高速缓冲存储器**==，用来存放最近访问的页表项的副本，以加速地址变换的过程
    + 与此对应，内存中的页表常称为慢表.
    + $TLB$和普通$Cache$的区别一一$TLB$中只有最近页表项的副本，而普通$Cache$中可能会有其他各种数据的副本
+ 由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间.
+ 因为局部性原理，一般来说快表的命中率可以达到$90\%$以上.
    + 时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问(因为程序中存在大量的循环).
    + 空间局部性:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问(因为很多数据在内存中都是连续存放的).
+ 有的系统支持快表和慢表同时查询，需要注意题上所给条件
+ 快表的地址变换过程:![image-20230623220657844](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306232206009.png)
    1. $CPU$给出逻辑地址，由某个硬件算得页号、页内偏移量，进行越界判断无异常后将页号与快表中的所有页号进行比较.
    2. 如果找到匹配的页号(即命中)，说明要访问的页表项在快表中有副本
        + 则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址
        + 最后访问该物理地址对应的内存单元
        + 因此==若快表命中则访问某个逻辑地址仅需一次访存即可==
    3. 如果没有找到匹配的页号
        1. 则需要访问**内存中**的页表，找到对应页表项，得到页面存放的内存块号
        2. 再将内存块号与页内偏移量拼接形成物理地址
        3. 最后，访问该物理地址对应的内存单元
        4. 同时将其存入快表，以便后面可能的再次访问
        5. 但若快表已满，则必须按照一定的页面置换算法对旧的页表项进行替换
        6. 因此，==若快表未命中，则访问某个逻辑地址需要两次访存.==

>   有些处理机设计为快表和慢表同时查找，若在快表中查找成功则终止慢表的查找

#### 多级页表

![image-20230623222414731](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306232224792.png)

单级页表的缺点:

1. 单级页表的所有表项都必须专门连续存储，因此当页表很大时，需要占用很多个连续的页框
2. 根据局部性原理，进程在一段时间内只需要访问少数页面就可用正常运行，无需整个页表都常驻内存.

将页表进行分组离散地放入内存块，并==为离散分组的页表再建立一张页表，称为**页目录表**、外层页表或顶层页表==，页目录表页保存页号和**内存块号**两项

两级页表结构的逻辑地址结构分为一级页号、二级页号和页内偏移量三项.

![image-20230623221820371](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306232218440.png)

地址转换过程:

1. 按照地址结构将逻辑地址拆分成三部分.
    1. 一级页号
    2. 二级页号
    3. 页内偏移量

2. 从$PCB$中读出页目录表始址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置(物理地址).
3. 根据二级页号查表，找到最终想访问的内存块号.
4. 根据内存块号结合页内偏移量得到物理地址.

注意点:

+ 若采用多级页表机制，则各级页表的大小不能超过**一个**页面
    + 因为顶级页表只能有一个，否则一个页面放不下页表项
    
    + 如果一个页面框放不下就需要多个页面框，而如果需要多个页面框就会导致多个页面框有相同的页号，就不能区分出哪个是顶级页表.

        ![image-20230623222257968](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306232222030.png)
    
+ 两级页表的访存次数分析(假设没有快表机构):
    1. 第一次访存:访问内存中的页目录表.
    2. 第二次访存:访问内存中的二级页表.
    3. 第三次访存:访问目标内存单元.

多级页表会使用页表基址寄存器$PTBR$来存储页表基址，此时$PTBR$会存储当前进程的一级页表的物理地址.

### 基本分段存储管理

![image-20230624220456655](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242204771.png)

#### 分段

+ 进程的地址空间
    + 按照程序自身的逻辑关系划分为若干个不等长的段，每个段都有一个段名
        + 在低级语言中，程序员使用段名来编程

    + 每段从$0$开始编址.

    + 对于地址空间段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的
    
+ 内存分配规则
    + 以段为单位进行分配，**每个段在内存中占据连续空间**，但各段之间可以不相邻

+ 分段系统的逻辑地址结构由段号(段名$S$)和段内地址(段内偏移量$W$)所组成.
    + 段号的位数决定了每个进程最多可以分几个
    + 段内地址位数决定了每个段的最大长度是多少.

+ 由于是按逻辑功能模块划分，**用户编程更方便，程序的可读性更高**

+ ==页式系统中逻辑地址的页号和页内偏移量对用户透明，但是段式系统段号和段内偏移量必须由用户显式提供，在高级程序设计语言中一般由编译程序完成.==

+ 段表
    + 程序分多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中找到各个逻辑段的存放位置
    
    + 为此，需为每个进程建立一张段映射表，简称“**段表**”:
        + 每个段对应一个段表项，其中记录了
            + 段号
                + **各个段表项的长度是相同的**.
                    + “**各个段表项的长度是相同的**”指的是段表项的长度，即段表里面段号+基址+段长的总长是相同的
                + 由于各个段表项的长度是相同的，因此段号可以是隐含的，**不占存储空间**
                
            + 该段在内存中的起始位置
                + 又称“基址”
            
            + 段的长度.
                + “**各个段表项的长度是相同的**”指的是**段表项**的长度，而非这里的**段的长度**
        
    + 即使段是共享的，但是不同的程序中使用，其段号也是不同的.
    
        ![image-20230901152814672](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011528739.png)
    
+ 配置段表后，执行中的进程可通过查找段表，找到每段所对应的内存区。

    + 可见，段表用于实现从逻辑段到物理内存区的映射，如图3.15所示。

        ![image-20230901152913008](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309011529120.png)


分段的优点:

+ 方便共享和保护.
+ 方便编程.
+ 方便动态链接和增长.

>   某系统按字节寻址，采用分段存储管理，逻辑地址结构为(段号$16$位，段内地址$16$位)，因此用$16$位即可表示最大段长
>
>   物理内存大小为$4GB$(可用$32$位表示整个物理内存地址空间)
>
>   因此，可以让每个段表项占$16+32=48$位，即$6B$
>
>   由于段表项长度相同，因此段号可以是隐含的，不占存储空间
>
>   若段表存放的起始地址为$R$，则$K$号段对应的段表项存放的地址为$R+K\times6$，段号并不占内存空间.

#### 段式存储地址变换

$CPU$执行指令时需要将逻辑地址变换为物理地址

![image-20230624215228083](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242152259.png)

1. 根据逻辑地址取出前几位为段号$S$和后几位为段内地址$W$.
    +   注意，在地址变换的题目中，要注意逻辑地址是用二进制数还是用十进制数给出的。
2. 检测段号越界中断
    + 根据段号$S$是否大于等于段表寄存器的段表长度$M$，判断上是否越界，若是则越界中断.
    + 段表长度至少为$1$
    + 段号范围$0\sim M-1$
3. 查询段表寄存器中的段表，找到对应的段表项
    + 段表项分为段长$C$和段基址$B$，段表项的存放地址$SA$=段表始值$F$+段号$S$×段表项长度$SL$.
4. 检测段长越界中断
    + 检测段内地址$W$是否大于等于段长$C$，若是则越界中断
    + 这也是段式存储与页式存储的最大不同，段式存储不定长
5. 计算得到物理地址$E$=段基址$B$+段内地址$W$.

#### 段的共享与保护

+   在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。

    +   不能修改的代码称为纯代码或可重入代码（它不属于临界资源），这样的代码和不能修改的数据可以共享，而可修改的代码和数据不能共享。 

+   与分页管理类似，分段管理的保护方法主要有两种：

    1.   一种是存取控制保护
    2.   另一种是地址越界保护
         +   地址越界保护将段表寄存器中的段表长度与逻辑地址中的段号比较，若==段号大于段表长度==，则产生越界中断
         +   再将段表项中的段长和逻辑地址中的段内偏移进行比较，若==段内偏移大于段长==，也会产生越界中断。

    +   分页管理只需要判断页号是否越界，页内偏移是不可能越界的。 

+   与页式管理不同，段式管理不能通过给出一个整数便确定对应的物理地址，因为==每段的长度是不固定的==，无法通过整数除法得出段号，无法通过求余得出段内偏移，所以段号和段内偏移一定要显式给出（段号，段内偏移），因此分段管理的地址空间是二维的。

#### 分段分页管理的对比

| &nbsp; |  与信息的关系  |           主要目的           |                        是否对用户可见                        |             长度             |                       用户进程地址空间                       | 示例汇编代码       |
| :----: | :------------: | :--------------------------: | :----------------------------------------------------------: | :--------------------------: | :----------------------------------------------------------: | ------------------ |
|  分页  | 信息的物理单位 | 实现离散分配，提高内存利用率 |   仅仅是系统管理上的需要，完全是系统行为，**对用户不可见**   |   页的大小固定且由系统决定   |      是一维的，程序员只需给出一个记忆符即可表示一个地址      | `LOAD 1，<A>;`     |
|  分段  | 信息的逻辑单位 |      更好地满足用户需求      | 一个段通常包含着一组属于一个逻辑模块的信息**分段对用户可见**，用户编程时需要显式地给出段名 | 不固定，决定于用户编写的程序 | 二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址. | `LOAD 1，[D]|<A>;` |

+ 分段比分页**更容易实现信息的共享和保护**.
    + 最大的优点
    + 只需让各进程的段表项指向同一个段即可实现共享.
    + 不能被修改的代码称为纯代码或可重入代码(不属于临界资源)，这样的代码是可以共享的
    + 可修改的代码是不能共享的
        + 当有一个代码段中有很多变量，各进程并发地同时访问可能造成数据不一致

+ 分页时页面不是按逻辑模块划分的，这就很难实现共享.
  
    ![image-20230624215947453](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242159524.png)


在计算地址时，段式存储的基址往往以十进制的位置给出，计算的结果需要与偏移量相加，最后转换为十六进制，页式存储的基址往往以十六进制的位置给出，计算的结果需要与偏移量直接拼接.

访问一个逻辑地址需要几次访存?

+ 分页(单级页表)

    1. 第一次访存
        + 查内存中的页表
    2. 第二次访存
        + 访问目标内存单元

    总共两次访存

+ 分段

    1. 第一次访存
        + 查内存中的段表
    2. 第二次访存
        + 访问目标内存单元

    总共两次访存

### 段页式存储管理

![image-20230624222633819](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242226927.png)

|  &nbsp;  |                           优点                           |                             缺点                             |
| :------: | :------------------------------------------------------: | :----------------------------------------------------------: |
| 分页管理 | 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 |            不方便按照逻辑模块实现信息的共享和保护            |
| 分段管理 |          很方便按照逻辑模块实现信息的共享和保护          | 如果段长过大，为其分配很大的连续空间会很不方便.另外，段式管理会产生外部碎片 |

分段管理中产生的外部碎片也可以用**紧凑**来解决，只是需要付出较大的时间代价

#### 段页式存储的过程

1. 将进程按逻辑模块分段，再将各段分页(如每个页面$4KB$).
2. 再将内存空间分为大小相同的内存块/页框/页帧/物理块.
3. 进程前将各页面分别装入各内存块中.

#### 段页式系统逻辑地址结构

+ 由段号$S$、页号$P$、页内地址$W$(页内偏移量)组成
    + 段号的位数决定了每个进程最多可以分几个段
    + 页号位数决定了每个段最大有多少页
    + 页内偏移量决定了页面大小、内存块大小是多少.
    + **【举例】：**
        + 若段号占$16$位，则在该系统中，每个进程最多有$2^16=61K$个段
        + 页号占$4$位，则每个段最多有$2^4=16$页
        + 页内偏移量占$12$位，则每个页面大小为$2^12=4096=4KB$

+ 系统含有一个段表寄存器，指出作业的段表始址和段表长度.
+ “分段”对用户是可见的，程序员编程时需要显式地给出段号、段内地址
    + 而将各段“分页”对用户是不可见的
    + 系统会根据段内地址自动划分页号和页内偏移量.

+ 因此段页式管理的地址结构是二维的.

地址表分为段表和页表，==段表只能有一个，页表可以有多个==：

+ 每个段对应一个**段表项**，每个段表项由段号、页表长度、页表存放块号(页表起始地址)组成
    + 每个段表项长度相等，段号是隐含的.

+ 每个页面对应一个**页表项，**每个页表项由页号、页面存放的内存块号组成
    + 每个页表项长度相等，页号是隐含的.

+ 一个进程对应**一个段表**，对应**一个或多个页表项**，一个段表项就相当于只存一个的页表寄存器.

#### 段页式存储地址变换过程

1. 根据逻辑地址得到段号$S$、页号$P$和页内偏移量$W$.
2. 检测段号越界中断
    + 根据段号$S$是否大于等于段表寄存器的段表长度$M$，判断上是否越界，若是则越界中断
    + 段表长度至少为$1$
3. 查询段表寄存器中的段表，找到对应的段表项.段表项分为段号$S$和页表长度$L$、段基址$F$和页表存放块号$D$
    + 段表项的存放地址$SA$=段表始值$F$+段号$S$×段表项长度$SL$.
4. 检测页号越界中断
    + 检测页号$P$是否大于等于页表项长度$PL$，若是则越界中断.
5. 根据页表存放块号$D$和页号$P$查询页表，找到对应页表项.页表项分为页号$P$和内存块号$B$.
6. 计算得到物理地址$E$=内存块号$B$+页内偏移量$W$.
7. 也可引入快表机构，用段号和页号作为查询快表的关键字.若快表命中则仅两次访存.

#### 覆盖技术*

覆盖技术在同一个程序或进程中执行.可以使用在单一连续分配和固定分区分配的方式.

+ 覆盖技术的思想
    + 将程序分为多个段(多个模块)
    + 常用的段常驻内存，不常用的段在需要时调入内存.

+ 内存中分为一个“固定区”和若干个“覆盖区”.
+ 需要常驻内存的段放在“固定区”中，调入后就不再调出(除非运行结束).
+ 不常用的段放在“覆盖区”，需要用到时调入内存，用不到时调出内存.
+ 按照自身代码逻辑结构，让那些不可能同时被访问的程序段共享同一个覆盖区.
+ 覆盖技术只用于早期的操作系统中，现在已成为历史.
+ 缺点:
    + 必须由程序员声明覆盖结构，操作系统完成自动覆盖.
    + 对用户不透明，增加了用户编程负担.

#### 交换技术*

交换技术在不同进程或作业之间进行的.

+ 交换(对换)技术的设计思想
    + 内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程**换入**内存
    + 进程在内存与磁盘间动态调度

+ 交换的位置
    + 具有对换功能的操作系统中，通常把磁盘空间分为**文件区**和**对换区**两部分
    + 文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式
    + 对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区
    + 由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式
    + 总之，对换区的$I/O$速度比文件区的更快.

+ 交换的时机
    + 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停
    + 例如在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程
    + 如果缺页率明显下降、就可以暂停换出.

+ 交换进程的选择
    + 可优先换出**阻塞进程**.
    + 可换出**优先级低**的进程.
    + 为了防止优先级低的进程在被调入内存后很快又被换出，考虑进程在内存的驻留时间.
+ 暂时换出外存等待的进程状态是挂起状态.
+ 处理机调度的中级调度(内存调度)就是交换技术的实现.
+ 进程的$PCB$常驻内存，不会被换出外存

覆盖用于同一个进程或程序中，交换用于不同进程或作业之间.

## 虚拟内存管理

虚拟存储技术使用局部性原理，用于对内存空间进行扩充，基于覆盖和交换技术.

传统存储管理特性：

+ 一次性：作业必须一次性全部装入内存后才能开始运行.这会造成两个问题：
    1. 作业很大时，不能全部装入内存，**导致大作业无法运行**.
    2. 当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致**导致多道程序并发度下降**.
+ 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束
    + 事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源.

高速缓冲技术的思想：将近期会频繁访问到的数据放到更高速的存储器中，暂时用不到的数据放在更低速存储器中.所以虚拟存储器技术不具备一次性和驻留性.

>   局部性原理
>
>   1.   时间局部性。
>        +   程序中的某条指令一旦执行，不久后该指令可能再次执行
>        +   某数据被访问过，不久后该数据可能再次被访问。
>        +   产生的原因是程序中存在着大量的循环操作。
>   2.   空间局部性。
>        +   一旦程序访问了某个存储单元，在不久后，其附近的存储单元也将被访问， 即程序在一段时间内所访问的地址，可能集中在一定的范围之内
>        +   因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。 

### 虚拟内存的基本概念

![image-20230624223600046](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242236154.png)

#### 虚拟内存定义

+ 基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行.
+ 在程序执行过程中，==当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存==，然后继续执行程序.
+ ==若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存==
+ ==虚拟存储技术是基于页或段从内存的调入/调出实现的，需要有请求机制的支持==
+ 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是**虚拟存储器/虚拟内存**
    + 这也是操作系统虚拟性的一个体现，实际的物理内存大小没有变，只是在逻辑上进行了扩充


#### 虚拟内存容量

+ 虚拟内存的最大容量是由计算机的**地址结构**($CPU$寻址范围)确定的=$CPU$寻址范围.
    + 与内存和外存容量无关

+ 虚拟内存的实际容量=$\min$(内存和外存容量之和，$CPU$寻址范围)
+ 某计算机地址结构为$32$位，按字节编址，内存大小为$512MB$，外存大小为$2GB$
    + 则虚拟内存的最大容量为$2^{32}B=4GB$，而实际内存是$2GB+512MB$.


#### 虚拟内存主要特征

+ 多次性
    + 无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存.
    + 解决了传统存储管理的一次性
    + ==多次性是虚拟存储器最重要的特征==
    
+ 对换性
    + 在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出.
    + 解决了传统存储管理的驻留性
    + 正是由于对换性，虚拟存储器才得以正常运行
    
+ 虚拟性
    + 从逻辑上扩充可内存的容量，使用户看到的内存容量，远大于实际的容量.
    + ==这是虚拟存储器所表现出的最重要特征，也是实现虚拟存储器的最重要目标==

#### 虚拟内存种类和实现

虚拟内存实现需要基于**离散分配**的内存管理方式基础上

>   采用连续分配方式时，会使相当一部分内存空间都处于暂时或"永久”的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量

所以根据传统的非连续分配存储管理，可以将虚拟存储的实现分为：

+ 请求分页存储管理.
+ 请求分段存储管理.
+ 请求段页式存储管理.

虚拟存储的实现与传统的非连续分配存储管理的主要区别是

+ 操作系统要提供请求调页/调段功能
    + 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序
+ 操作系统要提供页面/段置换的功能
    + 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存.所以操作系统需要提供请求调页或请求调段的功能与页面置换或段置换的功能.

==不管哪种方式，都需要有一定的硬件支持==，一般需要的支持有以下几个方面：

+ 一定容量的内存和外存.
+ 页表机制(或段表机制)，作为主要的数据结构.
+ 中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断.
+ 地址变换机构，逻辑地址到物理地址的变换.

### 请求分页管理方式

![image-20230624230048965](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242300080.png)

是最常用的实现虚拟存储器的方式，基于基本分页系统，增加了**请求调页**功能和**页面置换**功能.

#### 页表机制

+ 与基本分页管理相比，请求分页管理中，为了实现“请求调页”
    + 操作系统需要知道每个页面是否已经调入内存
    + 如果还没调入，那么也需要知道该页面在外存中存放的位置.

+ 当内存空间不够时，要实现“页面置换”
    + 操作系统需要通过某些指标来决定到底换出哪个页面
    + 有的页面没有被修改过，就不用再浪费时间写回外存
    + 有的页面修改过，就需要将外存中的旧数据覆盖
    + 因此，操作系统也需要记录各个页面是否被修改的信息.

请求分页管理存储的页表项分为：

![image-20230901231813617](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309012318689.png)

+ 页号(隐藏).
+ 内存块号/物理块号
+ 状态位$P$
    + 表示是否已调入内存，供访问时参考
    + $0$表示未调入，$1$表示已调入.

+ 访问字段$A$
    + 可记录最近被访问过几次，或记录上次访问的时间
    + 供置换算法选择换出页面时参考.

+ 修改位$M$
    + 页面调入内存后是否被修改过
    + $0$表示没有，$1$表示修改过.
    + 供置换算法选择换出页面时参考.
    
+ 外存地址
    + 页面在外存中的存放地址，一般是物理块号，供调入参考.


其中基本分页存储管理的页表项分为**隐藏的页号**与**内存块号/物理块号**，其余字段均为请求分页管理存储的页表项相比增加的，注意比较记忆

#### 缺页中断机构

在请求分页系统中，每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页调入内存

缺页中断作为中断，同样要经历诸如保护CPU环境、分析中断原因、转入缺页中断处理程序、恢复CPU环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别： 

1.   在指令执行期间而非一条指令执行完后产生和处理中断信号，属于内部异常。 
2.   一条指令在执行期间，可能产生多次缺页中断

1. 在请求分页系统中，每当要访问的**页面不在内存**时(状态位为$0$)
    + 便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断.
2. 此时缺页的进程阻塞，放入阻塞队列.
3. 如果内存中**有空闲块**
    + 则为进程**分配一个空闲块**，将所缺页面装入该块，并**修改页表中相应的页表项**
4. 如果内存中**没有空闲块**
    + 则由页面置换算法**选择一个页面淘汰**
    + 若该页面在内存期间**被修改过**，则要将其**写回外存**
    + 未修改过的页面不用写回外存.
5. 调页完成后再将其唤醒，放回就绪队列.

#### 地址变换机构

与普通页表的地址变换机构不同的是，增加了请求调页、页面置换和请求修改内容三个部分.

1. 计算逻辑地址$A$对应的页号$P$与页内偏移量$W$
    + 页号$P$=逻辑地址$A\div$页面长度
    + 页内偏移量$W$=$A$逻辑地址$\%$页面长度$L$
2. 检测页号$P$是否越界
    + 如果页号$P$大于等于页表长度$M$，则内中断
    + 因为页号从$0$开始，页表长度至少为$1$，从而$P=M$页会越界
        + 页号$P$范围为$0\sim M-1$
3. 在快表中查找对应页号
    + 如果找到匹配的页号(即命中)
        + 说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号
        + 再将内存块号与页内偏移量拼接形成物理地址
        + 最后，访问该物理地址对应的内存单元
        + 因此，==若快表命中，则访问某个逻辑地址仅需一次访存即可.==
    + 快表中有的页面一定是在内存中的.
4. 如果没有找到匹配的页号，则需要访问**内存中**的页表.
    + 访问内存一次
5. 找到对应页表项后
    + 若对应页面未调入内存，则产生缺页中断，之后由操作系统的缺页中断处理程序进行处理，包括调页与页面置换.
        + 若某个页面被换出外存，则快表中的相应表项也要删除，否则可能访问错误的页面.
6. 计算内存块号$B$
    + 根据页表寄存器中的页表项地址$PA$=页表起始地址$F$+页号$P$×页表项长度$PL$，得到页表中对应的页表项，从而确定页面存放的内存块号$B$.
7. 计算物理地址
    + 最后物理地址$E$=内存块号$B$×页面大小$L$+页内偏移量$W$
    + 如果内存块号和业内偏移量用二进制表示，则直接拼接起来就是最终物理地址了

简单而言，在具有快表机构的请求分页系统中，访问一个逻辑地址时，若发生缺页，则地址变换步骤是：

1. 查快表(未命中)
2. 查慢表(发现未调入内存)
3. 调页(调入的页面对应的表项会直接加入快表)
4. 查快表(命中)
5. 访问目标内存单元.

![image-20230624225824047](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242258126.png)

补充细节：

1. 只有“写指令”才需要修改“修改位”
    + 并且一般来说只需修改快表中的数据，只有要将快表项删除时才需要写回内存中的慢表，这样可以减少访存次数。
2. 和普通的中断处理一样，==缺页中断处理依然需要保留$CPU$现场==
3. 需要用某种“页面置换算法”来决定一个换出页面
4. ==换入/换出页面都需要启动慢速的$I/O$操作==
    + 如果换入/换出太频繁，会有很大的开销.
5. 页面调入内存后，需要修改慢表，同时也需要将表项复制到快表中。

### 页面分配策略

![image-20230624233804837](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242338962.png)

#### 页面分配、置换策略

+ 驻留集
    + 对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页都读入主存。因此，操作系统必须决定读取多少页，即决定给特定的进程分配几个页框。给一个进程分配的物理页框的集合就是这个进程的**驻留集**
    + 指请求分页存储管理中给进程分配的物理块的集合
    + ==即允许进入内存运行的最大物理块数量==
    + 每个进程都有一个对应于自己的驻留集

+ 在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小.
+ 分配驻留集大小需要考虑几点
    1.   分配给一个进程的页框越少（驻留集越小），驻留在主存中的进程就越多，从而可提高CPU的利用率。
    2.   若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少
    3.   驻留集太大，又会导致多道程序并发度下降，资源利用率降低
         +   由于局部性原理，对该进程的缺页率没有太明显的影响
+ 所以应该选择一个合适的驻留集大小.

页面分配策略：

+ **固定分配**：操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变
    + 即==驻留集大小不变==

+ **可变分配**：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少
    + 即==驻留集大小可变==


页面置换策略：

+ 局部置换：发生缺页时只能选==进程自己的物理块==进行置换.
+ 全局置换：可以将==操作系统保留的空闲物理块==分配给缺页进程，也可以将==别的进程持有的物理块==置换到外存，再分配给缺页进程.

所以结合页面分配策略与页面置换策略，可以得到：

+ 固定分配局部置换：==为每个进程分配一定数量的物理块，在整个运行期间都不改变==
    + 若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面.
    + 这种策略的缺点是
        + 很难在刚开始就确定应该为每个进程分配多少个物理块才算合理.
    + 采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数.
+ 可变分配全局置换：==只要缺页就给分配新物理块==
    + 刚开始会为每个进程分配一定数量的物理块
    + 操作系统会保持一个空闲物理块队列
    + 当某进程发生缺页时，从空闲物理块中取出一块分配给该进程
    + 若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程.
    + 采用这种策略时
        + 只要某进程发生缺页，都将获得新的物理块
        + 仅当空闲物理块用完时，系统才选择一个未锁定(即可以调出内存)的页面调出
        + 被选择调出的页可能是系统中任何一个进程中的页
        + ==因此这个被选中的其他进程拥有的物理块会减少，其他进程缺页率会增加.==
+ 可变分配局部置换：==要根据发生缺页的频率来动态地增加或减少进程的物理块==
    + 刚开始会为每个进程分配一定数量的物理块
    + 当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存.
        + 因此不会影响其他进程的运行
    + 如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度
    + 反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块.
+ ==没有固定分配全局置换策略，因为全局置换意味着进程拥有的物理块数量必然会改变，因此不可能是固定分配.==

>   页面分配策略在2015年的统考选择题中出现过，考查的是这三种策略的名称。往年很多读者看到这里时，由于认为不是重点，复习时便一带而过，最后在考试中失分。在这种基础题上失分是十分可惜的。再次提醒读者，考研成功的秘诀在于，'反复多次"和“全面

#### 物理块调入算法

采用固定分配策略时，将系统中的空闲物理块分配给各个进程，可采用下述几种算法。

1.   平均分配算法，将系统中所有可供分配的物理块平均分配给各个进程。
2.   按比例分配算法，根据进程的大小按比例分配物理块。
3.   优先权分配算法，为重要和紧迫的进程分配较多的物理块。通常采取的方法是把所有可分配的物理块分成两部分：一部分按比例分配给各个进程；一部分则根据优先权分配

#### 调入页面

调入页面时机：

+ 预调页策略(运行前)
    + 根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效
        + 主要指空间局部性，即如果当前访问了某个内存单元在之后很有可能会接着访问与其相邻的那些内存单元

    + 但如果提前调入的页面中大多数都没被访问过，则又是低效的
    + 因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有$50\%$左右
    + 故这种策略主要用于**进程的首次调入**，由程序员指出应该先调入哪些部分.

+ 请求调页策略(运行时)
    + 进程在运行期间发现缺页时才将所缺页面调入内存
    + 由这种策略调入的页面一定会被访问到
    + 但由于每次只能调入一页，而每次调页都要磁盘$I/O$操作，因此$I/O$开销较大.

+ 实际运行中预调页策略和请求调页策略会分别在不同时间点使用

调入页面位置：

+ 系统拥有足够的对换区空间
    + 页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快
    + 在进程运行前，需将进程相关的数据从文件区复制到对换区.

+ 系统缺少足够的对换区空间
    + 凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改
        + 因此换出时不必写回磁盘，下次需要时再从文件区调入即可

    + 对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入.

+ $UNIX$方式
    + 运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入
    + 若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入.

### 页面置换算法

![image-20230624232234000](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242322176.png)

假设一个例子，系统为某进程分配了三个内存块，并考虑到有一下页面号引用串(会依次访问这些页面)：
$$
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
$$
使用算法如何置换？

#### 最佳置换算法$OPT$

==每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率==

这是==不可能实际实现==的，因为不可能预测本进程所有页面请求，一般用来评价其他算法效果.

![image-20230624230511683](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242305758.png)

所以缺页中断发生了$9$次，页面置换发生了$6$次，缺页率$=9\div20=45\%$.

**【注意】：**

+ ==缺页时未必发生页面置换==。若还有可用的空闲内存块，就不用进行页面置换。
    + 例如上例中，前三次都是发生了缺页中断但都没有进行页面置换

#### 先进先出置换算法$FIFO$

每次选择淘汰的页面是==最早进入内存的页面，只考虑进入时间而不考虑访问次数==

实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可，队列的最大长度取决于系统为进程分配了多少个内存块.

![image-20230624230639587](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242306673.png)

缺页了$15$次，置换了$12$次，所以缺页率为$15\div20=75\%$.

假如给定一串页面号：$3，2，1，0，3，2，4，3，2，1，0，4$，使用$FIFO$算法进行置换

![image-20230624230720890](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242307959.png)

会发现分配三个内存块缺页次数为$9$次，而分配四个内存块缺页次数为$10$次.

+ 这种当为进程分配的**物理块数**增大时，缺页次数不减反增的异常现象就是**$Belady$异常**
+ 但是如果物理块尺寸增大一倍而块数不变，则在程序顺序执行时缺页中断次数会减少.
+ ==只有$FIFO$算法会产生$Belady$异常==
    + 对于顺序执行程序，缺页中断的次数等于其访问的页帧数，不会产生$Belady$异常

+ $FIFO$算法使用队列实现，是队列类算法
+ 另外，$FIFO$算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问
+ 因此该算法性能差.

#### 最近最久未使用置换算法$LRU$

每次淘汰的页面是**最近最久未使用**的页面.(是检查过去的，而$OPT$是检查未来的)

所以这里就需要使用页表中访问字段这一项，用来记录该页面自上次被访问以来所经历的时间$t$，当需要淘汰时，就选择$t$值最大的，即最近最久未使用的页面.

![image-20230624230924833](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242309922.png)

所以缺页中断发生了$12$次，页面置换发生了$9$次，缺页率$=12\div20=60\%$.

在手动做题时，若需要淘汰页面，可以逆向检查此时在内存中的几个页面号.在**逆向扫描过程中最后一个出现的页号就是要淘汰的页面.**

该算法的实现==要对所有页面进行排序，需要增加额外的$LRU$位(根本原因)，所以需要专门的硬件支持==，如寄存器和栈，虽然==算法性能好，最接近$OPT$算法==，但是==实现困难，开销大.==

#### 简单时钟置换算法$CLOCK$

即$CLOCK$算法.是一种性能和开销较均衡的算法，又称最近未用算法$NRU$，即对$LRU$的简化，只用管最近未使用即可，不用管最久.

实现方法：

1. 页面初始化

    1. 为每个页面设置一个访问位初始化全部为$1$

        + 访问位为$1$，表示最近访问过

        + 访问位为$0$，表示最近没访问过.

    2. 将内存中的页面都通过链接指针链接成一个循环队列.

    3. 当某页被访问时，其访问位置设为$1$.

2. 当内存满需要淘汰一个页面时

    1. 先检查页的访问位.
        + 如果是$0$，表示进入内存后一直没有访问过，就选择该页换出.
        + 如果是$1$，则将它置为$0$，暂不换出，继续检查下一个页面
    2. 若第一轮扫描中所有页面都是$1$，则将这些页面的访问位依次置为$0$后，再进行第二轮扫描.
    3. 第二轮扫描中一定会有访问位为$0$的页面，因此简单的$CLOCK$算法选择一个淘汰页面

值得注意的是：访问和置换是不同的，扫描指针用于置换，只有缺页中断才会发生指向的变化，而访问和修改数据是另一个指针，会随着访问而不断移动，且是访问指针会影响访问位而不是扫描指针.

假设系统为某进程分配了五个内存块，并考虑到有以下页面号引用串：
$$
7,0, 1,2, 0,3, 0,4, 2, 3, 0,3, 2, 1,3,2
$$
![image-20230902120232711](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309021202889.png)

+ 首次访问`7，0，1，2`时，产生缺页中断，依次调入主存，访问位都置为1。
+ 访问0时，已存在，访问位置为1。
+ 访问3时，产生第5次缺页中断，替换指针初始指向帧1，此时所有帧的访问位均为1，则替换指针完整地扫描一周，把所有帧的访问位都置为0，然后回到最初的位置（帧1），替换帧1中的页（包括置换页面和置访问位为1），如图3.27（a）所示。
+ 访问0时，已存在，访问位置为1。
+ 访问4时，产生第6次缺页中断，替换指针指向帧2 （上次替换位置的下一帧），帧2的访问位为1，将其修改为0，继续扫描，帧3的访问位为0，替换帧3中的页，如图3.27（b）所示。 
+ 然后依次访问`2，3，0，3，2`均已存在，每次访问都将其访问位置为1。
+ 访问1时，产生缺页中断， 替换指针指向帧4，此时所有帧的访问位均为1，又完整扫描一周并置访问位为0，回到帧4，替换之。
+ 访问3时，已存在，访问位置为1。
+ 访问2时，产生缺页中断，替换指针指向帧1，帧1的访问位为1，将其修改为0，继续扫描，帧2的访问位为0，替换帧2中的页

![image-20230902120449501](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309021204621.png)

简单的时钟置换算法仅考虑到一个页面最近是否被访问过，事实上，如果被淘汰的页面没有被修改过，就不需要执行$I/O$操作写回外存.只有被淘汰的页面被修改过时，才需要写回外存.

#### 改进型时钟置换算法

除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免$I/O$操作，这就是改进型的时钟置换算法的思想.

需要再追加一个修改位

+ 修改位$=0$，表示页面**没有被修改过**
+ 修改位$=1$，表示页面**被修改过**

为方便讨论，用**(访问位，修改位)**的形式表示各页面状态，如$(1，1)$表示一个页面近期被访问过，且被修改过.

算法规则：

1. 将所有可能被置换的页面排成一个循环队列
    + 初始的(访问位，修改位)可能是任何的$10$组合
    + 这和简单时钟算法初始为全$0$或全$1$不同.
2. 第一轮(**没访问没修改**)
    + 从当前位置开始扫描到第一个$(0，0)$的帧用于替换
    + 本轮扫描不修改任何标志位.
3. 第二轮(**没访问有修改**)
    + 若第一轮扫描失败，则重新扫描
    + 查找第一个$(0，1)$的帧用于替换
    + 本轮将所有扫描过的帧访问位设为$0$.
4. 第三轮(**有访问没修改**)
    + 若第二轮扫描失败，则重新扫描
    + 查找第一个$(0，0)$的帧用于替换
    + 本轮扫描不修改任何标志位.
5. 第四轮(**有访问有修改**)
    + 若第三轮扫描失败，则重新扫描
    + 查找第一个$(0，1)$的帧用于替换
    + 需要第四轮扫描只有全部页面都被访问都被修改过这一种情况.
6. 由于第二轮已将所有帧的访问位设为$0$，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改进型$CLOCK$置换算法选择一个淘汰页面最多会进行四轮扫描.

+ $(0，0)$：最近没有使用使用也没有修改，置换出内存的最佳选择
+ $(0，1)$：修改过但最近没有使用，将会被写.
+ >   第二轮会将所有扫描过的帧访问位设为$0$，所以下面两项的访问位在实际查找时会全为$0$
  
+ $(1，0)$：使用过但没有被修改，下一轮将再次被用.
+ $(1，1)$：使用过也修改过，下一轮页面置换最后的选择.


### 虚拟存储补充

#### 抖动(颠簸现象)

+ 刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为**抖动/颠簸**.
+ ==抖动的根本原因是，系统中同时运行的进程太多，由此分配给每个进程的物理块太少==，不能满足进程正常运行的基本要求，致使每个进程在运行时频繁地出现缺页，必须请求系统将所缺页面调入内存。
    + ==产生抖动的主要原因是页面置换算法不合理==

+ ==**所有**的页面置换算法都可能存在抖动.==
+ ==可以撤销部分进程来减缓抖动.==
+ 抖动是进程运行时出现的严重问题，必须采取相应的措施解决它。由于抖动的发生与系统为进程分配物理块的多少有关，于是又提出了关于**进程工作集**的概念

#### 进程工作集

+ 指在某段时间间隔里，进程实际访问页面的集合.

+ 窗口尺寸就是驻留集的大小，约束工作集大小，**工作集大小**小于等于**窗口尺寸/驻留集大小**
    + 实际应用中，操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块
    
    + 如窗口尺寸为$5$，经过一段时间的监测发现某进程的工作集最大为$3$，那么说明该进程有很好的局部性，可以给这个进程分配$3$个以上的内存块即可满足进程的运行需要.

        ![image-20230624233600084](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242336147.png)
    
+ 驻留集大小不能小于工作集大小，否则会产生抖动现象. 
    + 根据工作集大小确定驻留集大小

+ 在进程运行时，若其工作集页面都在**主存储器**内，则能够使该进程有效地运行，否则会出现频繁的页面调入调出现象.

+ 工作集模型的原理是，让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。

    + 落在工作集内的页面需要调入驻留集中，而落在工作集外的页面可从驻留集中换出。

    + 若还有空闲物理块，则可再调一个进程到内存。

    + 若所有进程的工作集之和超过了可用物理块总数，则操作系统会暂停一个进程，将其页面调出并将物理块分配给其他进程，防止出现抖动现象。

+ 基于局部性原理可知，进程在一段时间内访问的页面与不久之后会访问的页面是有相关性的，因此可以根据进程近期访问的页面集合(工作集)来设计一种页面置换算法——选择一个不在工作集中的页面进行淘汰.

>   **【注意】：工作集和驻留集**
>
>   + 驻留集：指请求分页存储管理中给进程分配的内存块的集合。
>   + 工作集：指在某段时间间隔里，进程实际访问页面的集合。
>   + 驻留集
>       + 对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页都读入主存。因此，操作系统必须决定读取多少页，即决定给特定的进程分配几个页框。给一个进程分配的物理页框的集合就是这个进程的**驻留集**
>       + 指请求分页存储管理中给进程分配的物理块的集合
>       + ==即允许进入内存运行的最大物理块数量==
>       + 每个进程都有一个对应于自己的驻留集

#### 内存映射文件

![image-20230624234839010](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242348089.png)

传统文件访问方式

- `open`系统调用：通过指定文件名和访问模式（如读取、写入、追加等），打开文件并返回文件描述符。
    - 文件描述符可以用于后续的文件读取和写入操作。

- `seek`系统调用：用于移动文件指针的位置，可以将文件指针定位到文件的任意位置。
    - `seek`系统调用通过指定偏移量和起始位置（如文件开头、当前位置、文件末尾等）来实现文件指针的移动。

- `read`系统调用：用于从文件中读取数据到指定的缓冲区。
    - `read`系统调用接受文件描述符、缓冲区和读取的字节数作为参数，将指定字节数的数据读取到缓冲区中，并更新文件指针的位置。


内存映射文件（$Memory-Mapped \;File$）是一种将文件映射到进程内存空间的机制，==可以将文件的内容直接映射到进程的虚拟内存中，使得文件的访问就像对内存的访问一样。==

- 内存映射文件的创建：通过使用`open`系统调用打开文件，并使用`mmap`系统调用将文件映射到内存空间。`mmap`系统调用返回一个指向映射区域的指针，该指针可以被用于后续的内存操作。
- 文件访问：通过操作内存映射区域来访问文件内容。进程可以直接读取和写入内存映射区域，而不需要使用`read`和`write`系统调用。对映射区域的修改也会直接反映到文件中，因为内存映射区域与文件内容是关联的。

1. 以访问内存的方式访问文件数据
2. 文件数据的读入、写出由操作系统自动完成
3. 进程关闭文件时，操作系统自动将文件被修改的数据写回磁盘



多个进程可以映射同一个文件，实现**共享**

![image-20230624234820548](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202306242348634.png)

#### 虚拟存储性能

+ 页面大小
    + 页面大：缺页率低，页表项占用少
    + 页面小：内部碎片少，利用率高.
+ 分配给进程的物理块数：合理数量的物理块.
+ 页面置换算法.
    + 好的页面置换算法可使进程在运行过程中具有较低的缺页率。
    + 选择LRU、CLOCK等置换算法，将未来有可能访问的页面尽量保留在内存中，从而提高页面的访问速度。 
+ 写回磁盘频率：系统中建立一个已修改换出页面的链表，一起写回，减少访存.
+ 程序局部化.
    + 编写程序的局部化程度越高，执行时的缺页率就越低。如果存储采用的是按行存储，访问时就要尽量采用相同的访问方式，避免按列访问造成缺页率过高的现象

### 地址翻译

>   设某系统满足以下条件
>
>   +   有一个 TLB 与一个 data Cache
>   +   存储器以字节为编址单位
>   +   虚拟地址14位
>   +   物理地址12位
>   +   页面大小为64B
>   +   TLB为四路组相联，共有16个条目
>   +   data Cache是物理寻址、直接映射的，行大小为4B，共有16组
>
>   写出访问地址为`0x03d4，0x00f1`和`0x0229`的过程

**【解】：**

+   因为本系统以字节编址，页面大小为64B，则页内偏移地址为$log_2(64B/1B) = 6$位
    +   所以虚拟页号为$14-6 = 8$位，物理页号为$12-6 = 6$位
+   因为TLB为四路组相联，共有16个条目，则TLB共有$16\div4 = 4$组，因此虚拟页号中低$log_24 = 2$位就为组索引，高6位就为TLB标记。
+   又因为Cache行大小为4B，因此物理地址中低$log_24 = 2$位为块偏移，Cache共有16组，可知接下来$log_216 = 4$位为组索引，剩下高6位作为标记。
+   地址结构如图3.29所示，TLB、页表、data Cache内容如表3.1、表3.2及表3.3所示。

![090212505145_01](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309021251933.png)

+   先把十六进制的虚拟地址`0x03d4，0x00f1`和`0x0229`转化为二进制形式，如表3.4所示。
+   得到每个地址的组索引和TLB标记，接下来就要找出每个地址的页面在不在主存中，若在主存中，则还要找出物理地址。 
    +   对于`0x03d4`，组索引为3， TLB标记为`0x03`，
        +   查TLB，第3组中正好有标记为03的项，有效位为1，可知页面在主存中，对应的物理页号为`0d (00 1101)`
        +   再拼接页内地址`01 0100`，可得物理地址为`0x354(0011 0101 0100)`
    +   对于`0x00f1`，组索引为3， TLB标记为`0x00`
        +   查TLB，第3组中没有标记为00的项
        +   再去找页表，虚拟页号为`0x03`，页表第3行的有效位为1，可知页面在主存中，物理页号为`02(00 0010)`
        +   再拼接页内地址`11 0001`，可得物理地址为`0x0b1(0000 1011 0001)`
    +   对于`0x0229`，组索引为0， TLB标记为`0x02`
        +   查TLB，第0组中没有标记为02的项，再去找页表，虚拟页号为`0x08`
        +   页表第8行的有效位为0，页面不在主存中产生缺页中断。 
+   找出在主存中的页面的物理地址后，就要通过物理地址访问数据，接下来要找该物理地址的内容在不在Cache中，物理地址结构如表3.5所示。

![image-20230902125333568](https://trouvaille-oss.oss-cn-beijing.aliyuncs.com/picList/202309021253670.png)

+   对于`0x354`， Cache索引为5， Cache标记为`Ox0d`，对照Cache中索引为5的行，标记正好为`0d`，有效位为1，可知该块在Cache中，偏移0，即块0，可得虚拟地址`0x03d4`的内容为`36H`。 
+   对于`Ox0b1`， Cache索引为c， Cache标记为`0x02`，对照Cache中索引为c的行，有效位为0，可知该块不在Cache中，要去主存中查找物理页号为2、偏移为`0x31`的内容。

### 小结

1.   覆盖技术与虚拟存储技术最本质的不同在于，覆盖程序段的最大长度要受内存容量大小的限制，而虚拟存储器中程序的最大长度不受内存容量的限制，只受计算机地址结构的限制。另外，覆盖技术中的覆盖段由程序员设计，且要求覆盖段中的各个覆盖具有相对独立性，不存在直接联系或相互交叉访问；而虚拟存储技术对用户的程序段没有这种要求。

2) 交换技术就是把暂时不用的某个程序及数据从内存移到外存中，以便腾出必要的内存空间，或把指定的程序或数据从外存读到内存中的一种内存扩充技术。交换技术与虚存中使用的调入/调出技术的主要相同点是，都要在内存与外存之间交换信息。交换技术与虚存中使用的调入/调出技术的主要区别是：交换技术调入/调出整个进程，因此一个进程的大小要受内存容量大小的限制；而虚存中使用的调入/调出技术在内存和外存之间来回传递的是页面或分段，而不是整个进程，从而使得进程的地址映射具有更大的灵活性，且允许进程的大小比可用的内存空间
